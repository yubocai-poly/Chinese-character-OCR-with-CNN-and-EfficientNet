{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chinese OCR simple testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "from alfred.utils.log import logger as logging\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load datasets\n",
    "load data from directory \"dataset\". The format is stored as tfrecord."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_example_v2(record):\n",
    "    \"\"\"\n",
    "    latest version format\n",
    "    :param record:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    features = tf.io.parse_single_example(record,\n",
    "                                          features={\n",
    "                                              'width':\n",
    "                                                  tf.io.FixedLenFeature([], tf.int64),\n",
    "                                              'height':\n",
    "                                                  tf.io.FixedLenFeature([], tf.int64),\n",
    "                                              'label':\n",
    "                                                  tf.io.FixedLenFeature([], tf.int64),\n",
    "                                              'image':\n",
    "                                                  tf.io.FixedLenFeature([], tf.string),\n",
    "                                          })\n",
    "    img = tf.io.decode_raw(features['image'], out_type=tf.uint8)\n",
    "    # we can not reshape since it stores with original size\n",
    "    w = features['width']\n",
    "    h = features['height']\n",
    "    img = tf.cast(tf.reshape(img, (w, h)), dtype=tf.float32)\n",
    "    label = tf.cast(features['label'], tf.int64)\n",
    "    return {'image': img, 'label': label}\n",
    "\n",
    "\n",
    "\n",
    "def load_ds(filedir):\n",
    "    input_files = [filedir]\n",
    "    ds = tf.data.TFRecordDataset(input_files)\n",
    "    ds = ds.map(parse_example_v2)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_ds('dataset/train.tfrecord') # read train.tfrecord\n",
    "test = load_ds('dataset/test.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RepeatDataset element_spec={'image': TensorSpec(shape=(None, None, None), dtype=tf.float32, name=None), 'label': TensorSpec(shape=(None,), dtype=tf.int64, name=None)}>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train\n",
    "test\n",
    "train_mapped = train.shuffle(100).batch(32).repeat()\n",
    "train_mapped\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\OCR'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some arguments\n",
    "target_size = 64\n",
    "num_classes = 7356\n",
    "# use_keras_fit = False\n",
    "use_keras_fit = True\n",
    "ckpt_path = './checkpoints/cn_ocr-{epoch}.ckpt'\n",
    "this_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "train_path = 'dataset/train.tfrecord'\n",
    "test_path = 'dataset/test.tfrecord'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_characters():\n",
    "    a = open(os.path.join(this_dir, 'dataset\\\\characters.txt'), 'r').readlines()\n",
    "    return [i.strip() for i in a]\n",
    "\n",
    "def preprocess(x):\n",
    "    \"\"\"\n",
    "    minus mean pixel or normalize?\n",
    "    \"\"\"\n",
    "    # original is 64x64, add a channel dim\n",
    "    x['image'] = tf.expand_dims(x['image'], axis=-1)\n",
    "    x['image'] = tf.image.resize(x['image'], (target_size, target_size))\n",
    "    x['image'] = (x['image'] - 128.) / 128.\n",
    "    return x['image'], x['label']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "# some simple models\n",
    "def build_net_001(input_shape, n_classes):\n",
    "    assert len(input_shape) == 3, 'only support 3 channels'\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(\n",
    "        input_shape=input_shape, filters=32, kernel_size=(3, 3), strides=(1, 1),\n",
    "        padding='valid', activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(n_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_net_002(input_shape, n_classes):\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Conv2D(input_shape=input_shape, filters=64, kernel_size=(3, 3), strides=(1, 1),\n",
    "                      padding='same', activation='relu'),\n",
    "        layers.MaxPool2D(pool_size=(2, 2), padding='same'),\n",
    "        layers.Conv2D(filters=128, kernel_size=(3, 3), padding='same'),\n",
    "        layers.MaxPool2D(pool_size=(2, 2), padding='same'),\n",
    "        layers.Conv2D(filters=256, kernel_size=(3, 3), padding='same'),\n",
    "        layers.MaxPool2D(pool_size=(2, 2), padding='same'),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1024, activation='relu'),\n",
    "        layers.Dense(n_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "# this model is converge in terms of chinese characters classification\n",
    "# so simply is effective sometimes, adding a dense maybe model will be better?\n",
    "def build_net_003(input_shape, n_classes):\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Conv2D(input_shape=input_shape, filters=32, kernel_size=(3, 3), strides=(1, 1),\n",
    "                      padding='same', activation='relu'),\n",
    "        layers.MaxPool2D(pool_size=(2, 2), padding='same'),\n",
    "        layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same'),\n",
    "        layers.MaxPool2D(pool_size=(2, 2), padding='same'),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        # layers.Dense(1024, activation='relu'),\n",
    "        layers.Dense(n_classes, activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train():\n",
    "    all_characters = load_characters()\n",
    "    num_classes = len(all_characters)\n",
    "    logging.info('all characters: {}'.format(num_classes))\n",
    "    train_dataset = load_ds(train_path)\n",
    "    train_dataset = train_dataset.shuffle(100).map(preprocess).batch(32).repeat()\n",
    "\n",
    "    val_ds = load_ds(test_path)\n",
    "    val_ds = val_ds.shuffle(100).map(preprocess).batch(32).repeat()\n",
    "    \n",
    "    for data in train_dataset.take(2):\n",
    "        print(data)\n",
    "\n",
    "    # init model\n",
    "    model = build_net_003((64, 64, 1), num_classes)\n",
    "    model.summary()\n",
    "    logging.info('model loaded.')\n",
    "\n",
    "    start_epoch = 0\n",
    "    latest_ckpt = tf.train.latest_checkpoint(os.path.dirname(ckpt_path))\n",
    "    if latest_ckpt:\n",
    "        start_epoch = int(latest_ckpt.split('-')[1].split('.')[0])\n",
    "        model.load_weights(latest_ckpt)\n",
    "        logging.info('model resumed from: {}, start at epoch: {}'.format(latest_ckpt, start_epoch))\n",
    "    else:\n",
    "        logging.info('passing resume since weights not there. training from scratch')\n",
    "\n",
    "    if use_keras_fit:\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(),\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "            metrics=['accuracy'])\n",
    "        callbacks = [\n",
    "            tf.keras.callbacks.ModelCheckpoint(ckpt_path,\n",
    "                                               save_weights_only=True,\n",
    "                                               verbose=1,\n",
    "                                               period=500)\n",
    "        ]\n",
    "        try:\n",
    "            model.fit(\n",
    "                train_dataset,\n",
    "                validation_data=val_ds,\n",
    "                validation_steps=1000,\n",
    "                epochs=15000,\n",
    "                steps_per_epoch=1024,\n",
    "                callbacks=callbacks)\n",
    "        except KeyboardInterrupt:\n",
    "            model.save_weights(ckpt_path.format(epoch=0))\n",
    "            logging.info('keras model saved.')\n",
    "        model.save_weights(ckpt_path.format(epoch=0))\n",
    "        model.save(os.path.join(os.path.dirname(ckpt_path), 'cn_ocr.h5'))\n",
    "    else:\n",
    "        loss_fn = tf.losses.SparseCategoricalCrossentropy()\n",
    "        optimizer = tf.optimizers.RMSprop()\n",
    "\n",
    "        train_loss = tf.metrics.Mean(name='train_loss')\n",
    "        train_accuracy = tf.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "        for epoch in range(start_epoch, 120):\n",
    "            try:\n",
    "                for batch, data in enumerate(train_dataset):\n",
    "                    # images, labels = data['image'], data['label']\n",
    "                    images, labels = data\n",
    "                    with tf.GradientTape() as tape:\n",
    "                        predictions = model(images)\n",
    "                        loss = loss_fn(labels, predictions)\n",
    "                    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "                    train_loss(loss)\n",
    "                    train_accuracy(labels, predictions)\n",
    "                    if batch % 10 == 0:\n",
    "                        logging.info('Epoch: {}, iter: {}, loss: {}, train_acc: {}'.format(\n",
    "                            epoch, batch, train_loss.result(), train_accuracy.result()))\n",
    "            except KeyboardInterrupt:\n",
    "                logging.info('interrupted.')\n",
    "                model.save_weights(ckpt_path.format(epoch=epoch))\n",
    "                logging.info('model saved into: {}'.format(ckpt_path.format(epoch=epoch)))\n",
    "                exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:19:33 05.08 \u001b[1mINFO\u001b[0m 1599783940.py:4]: all characters: 3755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(32, 64, 64, 1), dtype=float32, numpy=\n",
      "array([[[[ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         ...,\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ]],\n",
      "\n",
      "        [[ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         ...,\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ]],\n",
      "\n",
      "        [[ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         ...,\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         ...,\n",
      "         [ 0.22584534],\n",
      "         [ 0.5256119 ],\n",
      "         [ 0.8377762 ]],\n",
      "\n",
      "        [[ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         ...,\n",
      "         [-0.03772736],\n",
      "         [ 0.23122406],\n",
      "         [ 0.42704773]],\n",
      "\n",
      "        [[ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         ...,\n",
      "         [ 0.44918823],\n",
      "         [ 0.5025101 ],\n",
      "         [ 0.9161377 ]]],\n",
      "\n",
      "\n",
      "       [[[ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         ...,\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ]],\n",
      "\n",
      "        [[ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         ...,\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ]],\n",
      "\n",
      "        [[ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         ...,\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         ...,\n",
      "         [ 0.07491207],\n",
      "         [ 0.2705679 ],\n",
      "         [ 0.4057417 ]],\n",
      "\n",
      "        [[ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         ...,\n",
      "         [ 0.14594364],\n",
      "         [ 0.35743046],\n",
      "         [ 0.7878237 ]],\n",
      "\n",
      "        [[ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         ...,\n",
      "         [ 0.662035  ],\n",
      "         [ 0.84473515],\n",
      "         [ 0.9870472 ]]],\n",
      "\n",
      "\n",
      "       [[[ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         ...,\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ]],\n",
      "\n",
      "        [[ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         ...,\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ]],\n",
      "\n",
      "        [[ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         ...,\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         ...,\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ]],\n",
      "\n",
      "        [[ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         ...,\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ]],\n",
      "\n",
      "        [[ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         ...,\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         ...,\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ]],\n",
      "\n",
      "        [[ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         ...,\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ]],\n",
      "\n",
      "        [[ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         ...,\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         ...,\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ]],\n",
      "\n",
      "        [[ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         ...,\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ]],\n",
      "\n",
      "        [[ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         ...,\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ]]],\n",
      "\n",
      "\n",
      "       [[[ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         ...,\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ]],\n",
      "\n",
      "        [[ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         ...,\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ]],\n",
      "\n",
      "        [[ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         ...,\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         ...,\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ]],\n",
      "\n",
      "        [[ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         ...,\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ]],\n",
      "\n",
      "        [[ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         ...,\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ]]],\n",
      "\n",
      "\n",
      "       [[[ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         ...,\n",
      "         [ 0.8583822 ],\n",
      "         [ 0.22813702],\n",
      "         [ 0.95175266]],\n",
      "\n",
      "        [[ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         ...,\n",
      "         [ 0.3724432 ],\n",
      "         [ 0.34335613],\n",
      "         [ 0.8493366 ]],\n",
      "\n",
      "        [[ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         ...,\n",
      "         [ 0.36216354],\n",
      "         [ 0.45565224],\n",
      "         [ 0.8728266 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         ...,\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ]],\n",
      "\n",
      "        [[ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         ...,\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ]],\n",
      "\n",
      "        [[ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         ...,\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ],\n",
      "         [ 0.9921875 ]]]], dtype=float32)>, <tf.Tensor: shape=(32,), dtype=int64, numpy=\n",
      "array([3633, 1411, 1544, 1096, 2242, 2560, 2819,  358, 3681,   96,   92,\n",
      "       2599,  929, 3603,  935, 2039, 2464, 3138, 1557,   37, 3660,   35,\n",
      "       3389, 1313, 2554, 2788,   52,  469, 3052,  985, 1177, 2857],\n",
      "      dtype=int64)>)\n",
      "(<tf.Tensor: shape=(32, 64, 64, 1), dtype=float32, numpy=\n",
      "array([[[[0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         ...,\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ]],\n",
      "\n",
      "        [[0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         ...,\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ]],\n",
      "\n",
      "        [[0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         ...,\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.11132812],\n",
      "         [0.04640579],\n",
      "         [0.02138138],\n",
      "         ...,\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ]],\n",
      "\n",
      "        [[0.4831543 ],\n",
      "         [0.20647812],\n",
      "         [0.13435364],\n",
      "         ...,\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ]],\n",
      "\n",
      "        [[0.95703125],\n",
      "         [0.81624985],\n",
      "         [0.7654381 ],\n",
      "         ...,\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ]]],\n",
      "\n",
      "\n",
      "       [[[0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         ...,\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ]],\n",
      "\n",
      "        [[0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         ...,\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ]],\n",
      "\n",
      "        [[0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         ...,\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         ...,\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ]],\n",
      "\n",
      "        [[0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         ...,\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ]],\n",
      "\n",
      "        [[0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         ...,\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ]]],\n",
      "\n",
      "\n",
      "       [[[0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         ...,\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ]],\n",
      "\n",
      "        [[0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         ...,\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ]],\n",
      "\n",
      "        [[0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         ...,\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         ...,\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ]],\n",
      "\n",
      "        [[0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         ...,\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ]],\n",
      "\n",
      "        [[0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         ...,\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         ...,\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ]],\n",
      "\n",
      "        [[0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         ...,\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ]],\n",
      "\n",
      "        [[0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         ...,\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         ...,\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ]],\n",
      "\n",
      "        [[0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         ...,\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ]],\n",
      "\n",
      "        [[0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         ...,\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ]]],\n",
      "\n",
      "\n",
      "       [[[0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         ...,\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ]],\n",
      "\n",
      "        [[0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         ...,\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ]],\n",
      "\n",
      "        [[0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         ...,\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         ...,\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ]],\n",
      "\n",
      "        [[0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         ...,\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ]],\n",
      "\n",
      "        [[0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         ...,\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ]]],\n",
      "\n",
      "\n",
      "       [[[0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         ...,\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ]],\n",
      "\n",
      "        [[0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         ...,\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ]],\n",
      "\n",
      "        [[0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         ...,\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         ...,\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ]],\n",
      "\n",
      "        [[0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         ...,\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ]],\n",
      "\n",
      "        [[0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         ...,\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ],\n",
      "         [0.9921875 ]]]], dtype=float32)>, <tf.Tensor: shape=(32,), dtype=int64, numpy=\n",
      "array([2592,   84, 2312, 2478, 3303,  539,  815, 2340, 2786,  448,  721,\n",
      "       1677, 1554, 1518, 3479, 1412, 2539, 3418,  250, 1877,  262,  969,\n",
      "       2036,  286, 2321, 3106, 2880, 3040, 3596, 1309,  204,  548],\n",
      "      dtype=int64)>)\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_14 (Conv2D)          (None, 64, 64, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 3755)              61525675  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,544,491\n",
      "Trainable params: 61,544,491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:19:33 05.08 \u001b[1mINFO\u001b[0m 1599783940.py:17]: model loaded.\n",
      "11:19:33 05.08 \u001b[1mINFO\u001b[0m 1599783940.py:26]: passing resume since weights not there. training from scratch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/15000\n",
      "1024/1024 [==============================] - 19s 14ms/step - loss: 7.9613 - accuracy: 0.0011 - val_loss: 8.7710 - val_accuracy: 0.0159\n",
      "Epoch 2/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 5.4278 - accuracy: 0.1075 - val_loss: 7.0649 - val_accuracy: 0.0963\n",
      "Epoch 3/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 3.5483 - accuracy: 0.3143 - val_loss: 5.5893 - val_accuracy: 0.1768\n",
      "Epoch 4/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 3.2310 - accuracy: 0.3650 - val_loss: 6.5275 - val_accuracy: 0.1600\n",
      "Epoch 5/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 2.8150 - accuracy: 0.4286 - val_loss: 5.5337 - val_accuracy: 0.2012\n",
      "Epoch 6/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 3.2356 - accuracy: 0.3807 - val_loss: 6.1907 - val_accuracy: 0.2024\n",
      "Epoch 7/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 2.4519 - accuracy: 0.4931 - val_loss: 4.6738 - val_accuracy: 0.2426\n",
      "Epoch 8/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 2.3630 - accuracy: 0.4982 - val_loss: 4.2003 - val_accuracy: 0.2931\n",
      "Epoch 9/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 2.6946 - accuracy: 0.4495 - val_loss: 5.5981 - val_accuracy: 0.2227\n",
      "Epoch 10/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 2.4047 - accuracy: 0.5036 - val_loss: 4.3724 - val_accuracy: 0.2628\n",
      "Epoch 11/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 1.7283 - accuracy: 0.6163 - val_loss: 4.8437 - val_accuracy: 0.2920\n",
      "Epoch 12/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 1.7798 - accuracy: 0.6012 - val_loss: 4.6550 - val_accuracy: 0.2848\n",
      "Epoch 13/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 2.1826 - accuracy: 0.5417 - val_loss: 5.0496 - val_accuracy: 0.3146\n",
      "Epoch 14/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 2.1733 - accuracy: 0.5381 - val_loss: 4.3915 - val_accuracy: 0.3124\n",
      "Epoch 15/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 2.0373 - accuracy: 0.5626 - val_loss: 4.4683 - val_accuracy: 0.2940\n",
      "Epoch 16/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 2.0920 - accuracy: 0.5491 - val_loss: 5.7819 - val_accuracy: 0.2506\n",
      "Epoch 17/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 1.8803 - accuracy: 0.5867 - val_loss: 3.9378 - val_accuracy: 0.3272\n",
      "Epoch 18/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 1.7556 - accuracy: 0.6111 - val_loss: 4.1821 - val_accuracy: 0.3472\n",
      "Epoch 19/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 1.6471 - accuracy: 0.6318 - val_loss: 4.5840 - val_accuracy: 0.2766\n",
      "Epoch 20/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 1.4065 - accuracy: 0.6775 - val_loss: 4.9900 - val_accuracy: 0.2958\n",
      "Epoch 21/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 1.9683 - accuracy: 0.5724 - val_loss: 3.9435 - val_accuracy: 0.3491\n",
      "Epoch 22/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 1.4558 - accuracy: 0.6697 - val_loss: 3.5035 - val_accuracy: 0.4272\n",
      "Epoch 23/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 1.9063 - accuracy: 0.5914 - val_loss: 3.4241 - val_accuracy: 0.3825\n",
      "Epoch 24/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 1.8050 - accuracy: 0.6039 - val_loss: 3.5447 - val_accuracy: 0.3614\n",
      "Epoch 25/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 1.6365 - accuracy: 0.6323 - val_loss: 3.7255 - val_accuracy: 0.3629\n",
      "Epoch 26/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 1.5717 - accuracy: 0.6484 - val_loss: 4.9743 - val_accuracy: 0.2422\n",
      "Epoch 27/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 1.5056 - accuracy: 0.6541 - val_loss: 4.7146 - val_accuracy: 0.3326\n",
      "Epoch 28/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 1.6685 - accuracy: 0.6405 - val_loss: 3.4882 - val_accuracy: 0.4119\n",
      "Epoch 29/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.9258 - accuracy: 0.7787 - val_loss: 3.1440 - val_accuracy: 0.4389\n",
      "Epoch 30/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 1.1523 - accuracy: 0.7345 - val_loss: 3.4255 - val_accuracy: 0.4210\n",
      "Epoch 31/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.8386 - accuracy: 0.7967 - val_loss: 3.6330 - val_accuracy: 0.4180\n",
      "Epoch 32/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.7230 - accuracy: 0.8200 - val_loss: 3.8540 - val_accuracy: 0.3841\n",
      "Epoch 33/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 1.0002 - accuracy: 0.7770 - val_loss: 3.8468 - val_accuracy: 0.4092\n",
      "Epoch 34/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.8216 - accuracy: 0.8044 - val_loss: 6.0614 - val_accuracy: 0.2912\n",
      "Epoch 35/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.8793 - accuracy: 0.7920 - val_loss: 4.4123 - val_accuracy: 0.3675\n",
      "Epoch 36/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 1.0007 - accuracy: 0.7615 - val_loss: 3.8288 - val_accuracy: 0.4083\n",
      "Epoch 37/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.8638 - accuracy: 0.7945 - val_loss: 4.7356 - val_accuracy: 0.3778\n",
      "Epoch 38/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.7457 - accuracy: 0.8196 - val_loss: 3.7012 - val_accuracy: 0.4374\n",
      "Epoch 39/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.6160 - accuracy: 0.8437 - val_loss: 4.4928 - val_accuracy: 0.3729\n",
      "Epoch 40/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.7764 - accuracy: 0.8112 - val_loss: 4.2697 - val_accuracy: 0.3662\n",
      "Epoch 41/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.8096 - accuracy: 0.8038 - val_loss: 4.5527 - val_accuracy: 0.4009\n",
      "Epoch 42/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.7435 - accuracy: 0.8182 - val_loss: 5.6327 - val_accuracy: 0.2890\n",
      "Epoch 43/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.7429 - accuracy: 0.8181 - val_loss: 4.4826 - val_accuracy: 0.3826\n",
      "Epoch 44/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.7308 - accuracy: 0.8227 - val_loss: 4.8395 - val_accuracy: 0.3584\n",
      "Epoch 45/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.6561 - accuracy: 0.8334 - val_loss: 3.3696 - val_accuracy: 0.4613\n",
      "Epoch 46/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.6525 - accuracy: 0.8387 - val_loss: 4.1932 - val_accuracy: 0.4016\n",
      "Epoch 47/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.5204 - accuracy: 0.8647 - val_loss: 4.5740 - val_accuracy: 0.3937\n",
      "Epoch 48/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.7011 - accuracy: 0.8263 - val_loss: 3.7708 - val_accuracy: 0.4191\n",
      "Epoch 49/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.6012 - accuracy: 0.8478 - val_loss: 5.0891 - val_accuracy: 0.3598\n",
      "Epoch 50/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.4306 - accuracy: 0.8907 - val_loss: 7.5268 - val_accuracy: 0.1975\n",
      "Epoch 51/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.7020 - accuracy: 0.8311 - val_loss: 4.1950 - val_accuracy: 0.4193\n",
      "Epoch 52/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.7225 - accuracy: 0.8236 - val_loss: 5.9663 - val_accuracy: 0.3273\n",
      "Epoch 53/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.5793 - accuracy: 0.8535 - val_loss: 3.9045 - val_accuracy: 0.4526\n",
      "Epoch 54/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.6581 - accuracy: 0.8394 - val_loss: 3.8578 - val_accuracy: 0.4395\n",
      "Epoch 55/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.6292 - accuracy: 0.8437 - val_loss: 4.3086 - val_accuracy: 0.4232\n",
      "Epoch 56/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.4374 - accuracy: 0.8846 - val_loss: 4.2959 - val_accuracy: 0.4311\n",
      "Epoch 57/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.3556 - accuracy: 0.9072 - val_loss: 5.0793 - val_accuracy: 0.4076\n",
      "Epoch 58/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.3775 - accuracy: 0.8990 - val_loss: 4.2666 - val_accuracy: 0.4512\n",
      "Epoch 59/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.3303 - accuracy: 0.9084 - val_loss: 5.2259 - val_accuracy: 0.4135\n",
      "Epoch 60/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.4130 - accuracy: 0.8951 - val_loss: 5.7162 - val_accuracy: 0.3343\n",
      "Epoch 61/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.3631 - accuracy: 0.9019 - val_loss: 5.2895 - val_accuracy: 0.4057\n",
      "Epoch 62/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.3563 - accuracy: 0.9059 - val_loss: 4.8058 - val_accuracy: 0.3967\n",
      "Epoch 63/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.3634 - accuracy: 0.8998 - val_loss: 4.6473 - val_accuracy: 0.3939\n",
      "Epoch 64/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.3433 - accuracy: 0.9073 - val_loss: 4.9911 - val_accuracy: 0.3894\n",
      "Epoch 65/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.3504 - accuracy: 0.9044 - val_loss: 4.4869 - val_accuracy: 0.4137\n",
      "Epoch 66/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.2656 - accuracy: 0.9230 - val_loss: 4.8685 - val_accuracy: 0.4607\n",
      "Epoch 67/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.2976 - accuracy: 0.9185 - val_loss: 5.5612 - val_accuracy: 0.3667\n",
      "Epoch 68/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.3268 - accuracy: 0.9095 - val_loss: 4.9530 - val_accuracy: 0.4156\n",
      "Epoch 69/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.3179 - accuracy: 0.9150 - val_loss: 4.3324 - val_accuracy: 0.4533\n",
      "Epoch 70/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.3502 - accuracy: 0.9040 - val_loss: 5.1677 - val_accuracy: 0.4008\n",
      "Epoch 71/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.3348 - accuracy: 0.9079 - val_loss: 5.4394 - val_accuracy: 0.4010\n",
      "Epoch 72/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.3485 - accuracy: 0.9102 - val_loss: 5.4334 - val_accuracy: 0.3946\n",
      "Epoch 73/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.2581 - accuracy: 0.9291 - val_loss: 4.6825 - val_accuracy: 0.4456\n",
      "Epoch 74/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.2857 - accuracy: 0.9205 - val_loss: 5.4998 - val_accuracy: 0.4105\n",
      "Epoch 75/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.2886 - accuracy: 0.9199 - val_loss: 4.5723 - val_accuracy: 0.4293\n",
      "Epoch 76/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.2903 - accuracy: 0.9196 - val_loss: 6.7796 - val_accuracy: 0.3477\n",
      "Epoch 77/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.2083 - accuracy: 0.9406 - val_loss: 4.7552 - val_accuracy: 0.4626\n",
      "Epoch 78/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.3057 - accuracy: 0.9179 - val_loss: 6.1987 - val_accuracy: 0.3750\n",
      "Epoch 79/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.2819 - accuracy: 0.9209 - val_loss: 5.0273 - val_accuracy: 0.4120\n",
      "Epoch 80/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.2310 - accuracy: 0.9355 - val_loss: 4.9484 - val_accuracy: 0.4309\n",
      "Epoch 81/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.2401 - accuracy: 0.9334 - val_loss: 4.6258 - val_accuracy: 0.4605\n",
      "Epoch 82/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.2526 - accuracy: 0.9285 - val_loss: 4.6898 - val_accuracy: 0.4831\n",
      "Epoch 83/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.2649 - accuracy: 0.9275 - val_loss: 4.5473 - val_accuracy: 0.4775\n",
      "Epoch 84/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1966 - accuracy: 0.9457 - val_loss: 5.1659 - val_accuracy: 0.4341\n",
      "Epoch 85/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.2148 - accuracy: 0.9397 - val_loss: 5.2532 - val_accuracy: 0.4454\n",
      "Epoch 86/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.2034 - accuracy: 0.9429 - val_loss: 5.3439 - val_accuracy: 0.4463\n",
      "Epoch 87/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.2148 - accuracy: 0.9410 - val_loss: 6.6897 - val_accuracy: 0.3543\n",
      "Epoch 88/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.2392 - accuracy: 0.9346 - val_loss: 5.3544 - val_accuracy: 0.4251\n",
      "Epoch 89/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.2179 - accuracy: 0.9402 - val_loss: 5.7679 - val_accuracy: 0.4130\n",
      "Epoch 90/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.2187 - accuracy: 0.9392 - val_loss: 5.2913 - val_accuracy: 0.4518\n",
      "Epoch 91/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.2536 - accuracy: 0.9300 - val_loss: 5.5142 - val_accuracy: 0.4294\n",
      "Epoch 92/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.2263 - accuracy: 0.9350 - val_loss: 5.8885 - val_accuracy: 0.3947\n",
      "Epoch 93/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1913 - accuracy: 0.9466 - val_loss: 5.1536 - val_accuracy: 0.4319\n",
      "Epoch 94/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1929 - accuracy: 0.9449 - val_loss: 5.4422 - val_accuracy: 0.4495\n",
      "Epoch 95/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.2206 - accuracy: 0.9360 - val_loss: 5.0911 - val_accuracy: 0.4470\n",
      "Epoch 96/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.2058 - accuracy: 0.9430 - val_loss: 5.6579 - val_accuracy: 0.4223\n",
      "Epoch 97/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.2091 - accuracy: 0.9406 - val_loss: 5.5882 - val_accuracy: 0.4300\n",
      "Epoch 98/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.2306 - accuracy: 0.9352 - val_loss: 5.8380 - val_accuracy: 0.4194\n",
      "Epoch 99/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.2362 - accuracy: 0.9353 - val_loss: 5.0373 - val_accuracy: 0.4545\n",
      "Epoch 100/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1939 - accuracy: 0.9462 - val_loss: 4.7989 - val_accuracy: 0.4635\n",
      "Epoch 101/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1665 - accuracy: 0.9504 - val_loss: 4.9085 - val_accuracy: 0.4493\n",
      "Epoch 102/15000\n",
      "1024/1024 [==============================] - 15s 14ms/step - loss: 0.1701 - accuracy: 0.9523 - val_loss: 5.2697 - val_accuracy: 0.4673\n",
      "Epoch 103/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1707 - accuracy: 0.9495 - val_loss: 4.9499 - val_accuracy: 0.4581\n",
      "Epoch 104/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1660 - accuracy: 0.9522 - val_loss: 5.7256 - val_accuracy: 0.4262\n",
      "Epoch 105/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1491 - accuracy: 0.9572 - val_loss: 6.6737 - val_accuracy: 0.3561\n",
      "Epoch 106/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1583 - accuracy: 0.9542 - val_loss: 6.3047 - val_accuracy: 0.4185\n",
      "Epoch 107/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1328 - accuracy: 0.9613 - val_loss: 5.5495 - val_accuracy: 0.4570\n",
      "Epoch 108/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1487 - accuracy: 0.9563 - val_loss: 6.4861 - val_accuracy: 0.3966\n",
      "Epoch 109/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1569 - accuracy: 0.9559 - val_loss: 5.6570 - val_accuracy: 0.4433\n",
      "Epoch 110/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1529 - accuracy: 0.9559 - val_loss: 5.1466 - val_accuracy: 0.4690\n",
      "Epoch 111/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1230 - accuracy: 0.9636 - val_loss: 5.5374 - val_accuracy: 0.4464\n",
      "Epoch 112/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1534 - accuracy: 0.9575 - val_loss: 5.7279 - val_accuracy: 0.4581\n",
      "Epoch 113/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1327 - accuracy: 0.9609 - val_loss: 5.8604 - val_accuracy: 0.4568\n",
      "Epoch 114/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1589 - accuracy: 0.9554 - val_loss: 6.3032 - val_accuracy: 0.4477\n",
      "Epoch 115/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1822 - accuracy: 0.9512 - val_loss: 6.0385 - val_accuracy: 0.4441\n",
      "Epoch 116/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1551 - accuracy: 0.9549 - val_loss: 6.3029 - val_accuracy: 0.4410\n",
      "Epoch 117/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1693 - accuracy: 0.9551 - val_loss: 6.0540 - val_accuracy: 0.4515\n",
      "Epoch 118/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1602 - accuracy: 0.9538 - val_loss: 5.9800 - val_accuracy: 0.4188\n",
      "Epoch 119/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1614 - accuracy: 0.9565 - val_loss: 5.7773 - val_accuracy: 0.4168\n",
      "Epoch 120/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1491 - accuracy: 0.9583 - val_loss: 5.6158 - val_accuracy: 0.4492\n",
      "Epoch 121/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1438 - accuracy: 0.9604 - val_loss: 5.7982 - val_accuracy: 0.4408\n",
      "Epoch 122/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1297 - accuracy: 0.9618 - val_loss: 5.8928 - val_accuracy: 0.4515\n",
      "Epoch 123/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1507 - accuracy: 0.9570 - val_loss: 5.7972 - val_accuracy: 0.4415\n",
      "Epoch 124/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1498 - accuracy: 0.9586 - val_loss: 5.4556 - val_accuracy: 0.4392\n",
      "Epoch 125/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1557 - accuracy: 0.9539 - val_loss: 7.0739 - val_accuracy: 0.3615\n",
      "Epoch 126/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1442 - accuracy: 0.9572 - val_loss: 5.7597 - val_accuracy: 0.4286\n",
      "Epoch 127/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1482 - accuracy: 0.9595 - val_loss: 5.4186 - val_accuracy: 0.4618\n",
      "Epoch 128/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1212 - accuracy: 0.9644 - val_loss: 5.7356 - val_accuracy: 0.4462\n",
      "Epoch 129/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1167 - accuracy: 0.9666 - val_loss: 5.2092 - val_accuracy: 0.4793\n",
      "Epoch 130/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1169 - accuracy: 0.9642 - val_loss: 5.5109 - val_accuracy: 0.4458\n",
      "Epoch 131/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1207 - accuracy: 0.9638 - val_loss: 5.6743 - val_accuracy: 0.4378\n",
      "Epoch 132/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0896 - accuracy: 0.9739 - val_loss: 5.6553 - val_accuracy: 0.4789\n",
      "Epoch 133/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1107 - accuracy: 0.9667 - val_loss: 5.8691 - val_accuracy: 0.4417\n",
      "Epoch 134/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1051 - accuracy: 0.9692 - val_loss: 5.7409 - val_accuracy: 0.4548\n",
      "Epoch 135/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0962 - accuracy: 0.9720 - val_loss: 5.8106 - val_accuracy: 0.4607\n",
      "Epoch 136/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1070 - accuracy: 0.9698 - val_loss: 5.7234 - val_accuracy: 0.4553\n",
      "Epoch 137/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1107 - accuracy: 0.9672 - val_loss: 6.0944 - val_accuracy: 0.4024\n",
      "Epoch 138/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0848 - accuracy: 0.9739 - val_loss: 5.5054 - val_accuracy: 0.4801\n",
      "Epoch 139/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1243 - accuracy: 0.9670 - val_loss: 5.7596 - val_accuracy: 0.4622\n",
      "Epoch 140/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1031 - accuracy: 0.9703 - val_loss: 6.1278 - val_accuracy: 0.4485\n",
      "Epoch 141/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1125 - accuracy: 0.9707 - val_loss: 5.9171 - val_accuracy: 0.4690\n",
      "Epoch 142/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1193 - accuracy: 0.9668 - val_loss: 6.5733 - val_accuracy: 0.4317\n",
      "Epoch 143/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1302 - accuracy: 0.9631 - val_loss: 6.7472 - val_accuracy: 0.4248\n",
      "Epoch 144/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1176 - accuracy: 0.9675 - val_loss: 6.6965 - val_accuracy: 0.4135\n",
      "Epoch 145/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1081 - accuracy: 0.9691 - val_loss: 6.1921 - val_accuracy: 0.4544\n",
      "Epoch 146/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1318 - accuracy: 0.9643 - val_loss: 6.9323 - val_accuracy: 0.4045\n",
      "Epoch 147/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1205 - accuracy: 0.9670 - val_loss: 6.8430 - val_accuracy: 0.4239\n",
      "Epoch 148/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1086 - accuracy: 0.9699 - val_loss: 6.9034 - val_accuracy: 0.4365\n",
      "Epoch 149/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0945 - accuracy: 0.9729 - val_loss: 6.6794 - val_accuracy: 0.4422\n",
      "Epoch 150/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1177 - accuracy: 0.9670 - val_loss: 6.3592 - val_accuracy: 0.4611\n",
      "Epoch 151/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1097 - accuracy: 0.9694 - val_loss: 6.7410 - val_accuracy: 0.4478\n",
      "Epoch 152/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1128 - accuracy: 0.9662 - val_loss: 6.1815 - val_accuracy: 0.4386\n",
      "Epoch 153/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1210 - accuracy: 0.9659 - val_loss: 6.5878 - val_accuracy: 0.4315\n",
      "Epoch 154/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1170 - accuracy: 0.9667 - val_loss: 6.4131 - val_accuracy: 0.4576\n",
      "Epoch 155/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0925 - accuracy: 0.9742 - val_loss: 6.2092 - val_accuracy: 0.4461\n",
      "Epoch 156/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0948 - accuracy: 0.9727 - val_loss: 6.0919 - val_accuracy: 0.4553\n",
      "Epoch 157/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0874 - accuracy: 0.9751 - val_loss: 6.9924 - val_accuracy: 0.4107\n",
      "Epoch 158/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1000 - accuracy: 0.9698 - val_loss: 6.3548 - val_accuracy: 0.4476\n",
      "Epoch 159/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0829 - accuracy: 0.9754 - val_loss: 5.9367 - val_accuracy: 0.4730\n",
      "Epoch 160/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0779 - accuracy: 0.9781 - val_loss: 6.3514 - val_accuracy: 0.4458\n",
      "Epoch 161/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0875 - accuracy: 0.9763 - val_loss: 6.3258 - val_accuracy: 0.4196\n",
      "Epoch 162/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0657 - accuracy: 0.9797 - val_loss: 6.3613 - val_accuracy: 0.4445\n",
      "Epoch 163/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0887 - accuracy: 0.9751 - val_loss: 6.4543 - val_accuracy: 0.4570\n",
      "Epoch 164/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0878 - accuracy: 0.9753 - val_loss: 6.7000 - val_accuracy: 0.4579\n",
      "Epoch 165/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0802 - accuracy: 0.9777 - val_loss: 6.5255 - val_accuracy: 0.4299\n",
      "Epoch 166/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0786 - accuracy: 0.9792 - val_loss: 6.9177 - val_accuracy: 0.4412\n",
      "Epoch 167/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0876 - accuracy: 0.9750 - val_loss: 6.6108 - val_accuracy: 0.4626\n",
      "Epoch 168/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0920 - accuracy: 0.9759 - val_loss: 6.7180 - val_accuracy: 0.4672\n",
      "Epoch 169/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0803 - accuracy: 0.9776 - val_loss: 7.2392 - val_accuracy: 0.4349\n",
      "Epoch 170/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1244 - accuracy: 0.9678 - val_loss: 7.5923 - val_accuracy: 0.4336\n",
      "Epoch 171/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0904 - accuracy: 0.9752 - val_loss: 8.2310 - val_accuracy: 0.4136\n",
      "Epoch 172/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1102 - accuracy: 0.9730 - val_loss: 8.0440 - val_accuracy: 0.4086\n",
      "Epoch 173/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1166 - accuracy: 0.9688 - val_loss: 6.9860 - val_accuracy: 0.4556\n",
      "Epoch 174/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1084 - accuracy: 0.9704 - val_loss: 7.6154 - val_accuracy: 0.4132\n",
      "Epoch 175/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0986 - accuracy: 0.9734 - val_loss: 7.1981 - val_accuracy: 0.4533\n",
      "Epoch 176/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0951 - accuracy: 0.9744 - val_loss: 7.0384 - val_accuracy: 0.4420\n",
      "Epoch 177/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0932 - accuracy: 0.9737 - val_loss: 7.7678 - val_accuracy: 0.3860\n",
      "Epoch 178/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0874 - accuracy: 0.9751 - val_loss: 7.2707 - val_accuracy: 0.4428\n",
      "Epoch 179/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0985 - accuracy: 0.9732 - val_loss: 8.6057 - val_accuracy: 0.3605\n",
      "Epoch 180/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0934 - accuracy: 0.9740 - val_loss: 6.8706 - val_accuracy: 0.4490\n",
      "Epoch 181/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0960 - accuracy: 0.9738 - val_loss: 7.0262 - val_accuracy: 0.4524\n",
      "Epoch 182/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0919 - accuracy: 0.9751 - val_loss: 7.0140 - val_accuracy: 0.4491\n",
      "Epoch 183/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0796 - accuracy: 0.9775 - val_loss: 6.4839 - val_accuracy: 0.4801\n",
      "Epoch 184/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0760 - accuracy: 0.9792 - val_loss: 7.8097 - val_accuracy: 0.4342\n",
      "Epoch 185/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0947 - accuracy: 0.9747 - val_loss: 6.8302 - val_accuracy: 0.4306\n",
      "Epoch 186/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0713 - accuracy: 0.9792 - val_loss: 7.2971 - val_accuracy: 0.4487\n",
      "Epoch 187/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0642 - accuracy: 0.9821 - val_loss: 7.4374 - val_accuracy: 0.4225\n",
      "Epoch 188/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0728 - accuracy: 0.9793 - val_loss: 7.2784 - val_accuracy: 0.4557\n",
      "Epoch 189/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0698 - accuracy: 0.9797 - val_loss: 9.3360 - val_accuracy: 0.3556\n",
      "Epoch 190/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0736 - accuracy: 0.9796 - val_loss: 7.5835 - val_accuracy: 0.4376\n",
      "Epoch 191/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0829 - accuracy: 0.9774 - val_loss: 7.3115 - val_accuracy: 0.4418\n",
      "Epoch 192/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0737 - accuracy: 0.9791 - val_loss: 6.8534 - val_accuracy: 0.4575\n",
      "Epoch 193/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0606 - accuracy: 0.9827 - val_loss: 7.1913 - val_accuracy: 0.4623\n",
      "Epoch 194/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0925 - accuracy: 0.9762 - val_loss: 7.5990 - val_accuracy: 0.4495\n",
      "Epoch 195/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0751 - accuracy: 0.9800 - val_loss: 7.5341 - val_accuracy: 0.4577\n",
      "Epoch 196/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0838 - accuracy: 0.9793 - val_loss: 7.7802 - val_accuracy: 0.4544\n",
      "Epoch 197/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0973 - accuracy: 0.9755 - val_loss: 8.4914 - val_accuracy: 0.4047\n",
      "Epoch 198/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0795 - accuracy: 0.9786 - val_loss: 8.5439 - val_accuracy: 0.4293\n",
      "Epoch 199/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0962 - accuracy: 0.9769 - val_loss: 8.6212 - val_accuracy: 0.4133\n",
      "Epoch 200/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0924 - accuracy: 0.9755 - val_loss: 8.2336 - val_accuracy: 0.4187\n",
      "Epoch 201/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.1025 - accuracy: 0.9736 - val_loss: 8.0536 - val_accuracy: 0.4351\n",
      "Epoch 202/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0987 - accuracy: 0.9746 - val_loss: 8.2354 - val_accuracy: 0.4371\n",
      "Epoch 203/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0745 - accuracy: 0.9797 - val_loss: 8.9362 - val_accuracy: 0.4394\n",
      "Epoch 204/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0928 - accuracy: 0.9766 - val_loss: 8.1597 - val_accuracy: 0.4208\n",
      "Epoch 205/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0826 - accuracy: 0.9784 - val_loss: 8.0398 - val_accuracy: 0.4268\n",
      "Epoch 206/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0747 - accuracy: 0.9797 - val_loss: 8.0506 - val_accuracy: 0.4371\n",
      "Epoch 207/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0864 - accuracy: 0.9765 - val_loss: 8.9791 - val_accuracy: 0.3892\n",
      "Epoch 208/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0761 - accuracy: 0.9785 - val_loss: 8.1598 - val_accuracy: 0.4187\n",
      "Epoch 209/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0866 - accuracy: 0.9784 - val_loss: 8.1387 - val_accuracy: 0.4369\n",
      "Epoch 210/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0727 - accuracy: 0.9802 - val_loss: 9.0541 - val_accuracy: 0.4232\n",
      "Epoch 211/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0702 - accuracy: 0.9810 - val_loss: 7.6406 - val_accuracy: 0.4521\n",
      "Epoch 212/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0759 - accuracy: 0.9792 - val_loss: 7.0516 - val_accuracy: 0.4550\n",
      "Epoch 213/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0647 - accuracy: 0.9815 - val_loss: 9.4475 - val_accuracy: 0.3898\n",
      "Epoch 214/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0510 - accuracy: 0.9862 - val_loss: 7.5976 - val_accuracy: 0.4617\n",
      "Epoch 215/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0681 - accuracy: 0.9821 - val_loss: 8.1733 - val_accuracy: 0.4310\n",
      "Epoch 216/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0694 - accuracy: 0.9818 - val_loss: 7.9087 - val_accuracy: 0.4182\n",
      "Epoch 217/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0669 - accuracy: 0.9810 - val_loss: 7.7436 - val_accuracy: 0.4511\n",
      "Epoch 218/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0679 - accuracy: 0.9815 - val_loss: 7.6752 - val_accuracy: 0.4472\n",
      "Epoch 219/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0689 - accuracy: 0.9813 - val_loss: 8.2017 - val_accuracy: 0.4459\n",
      "Epoch 220/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0622 - accuracy: 0.9830 - val_loss: 7.4512 - val_accuracy: 0.4723\n",
      "Epoch 221/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0638 - accuracy: 0.9827 - val_loss: 8.1199 - val_accuracy: 0.4429\n",
      "Epoch 222/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0683 - accuracy: 0.9820 - val_loss: 7.8153 - val_accuracy: 0.4656\n",
      "Epoch 223/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0673 - accuracy: 0.9830 - val_loss: 8.1733 - val_accuracy: 0.4533\n",
      "Epoch 224/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0757 - accuracy: 0.9811 - val_loss: 9.2651 - val_accuracy: 0.4122\n",
      "Epoch 225/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0861 - accuracy: 0.9786 - val_loss: 8.9537 - val_accuracy: 0.4303\n",
      "Epoch 226/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0722 - accuracy: 0.9807 - val_loss: 9.3175 - val_accuracy: 0.4263\n",
      "Epoch 227/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0995 - accuracy: 0.9772 - val_loss: 8.5927 - val_accuracy: 0.4554\n",
      "Epoch 228/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0983 - accuracy: 0.9754 - val_loss: 8.7486 - val_accuracy: 0.4366\n",
      "Epoch 229/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0821 - accuracy: 0.9789 - val_loss: 9.6653 - val_accuracy: 0.3944\n",
      "Epoch 230/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0820 - accuracy: 0.9805 - val_loss: 9.4121 - val_accuracy: 0.4178\n",
      "Epoch 231/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0822 - accuracy: 0.9805 - val_loss: 8.5101 - val_accuracy: 0.4591\n",
      "Epoch 232/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0783 - accuracy: 0.9795 - val_loss: 8.4894 - val_accuracy: 0.4400\n",
      "Epoch 233/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0763 - accuracy: 0.9800 - val_loss: 8.5352 - val_accuracy: 0.4379\n",
      "Epoch 234/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0670 - accuracy: 0.9828 - val_loss: 9.1939 - val_accuracy: 0.4331\n",
      "Epoch 235/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0853 - accuracy: 0.9779 - val_loss: 8.5960 - val_accuracy: 0.4316\n",
      "Epoch 236/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0722 - accuracy: 0.9811 - val_loss: 8.0824 - val_accuracy: 0.4551\n",
      "Epoch 237/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0653 - accuracy: 0.9838 - val_loss: 7.7324 - val_accuracy: 0.4610\n",
      "Epoch 238/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0639 - accuracy: 0.9832 - val_loss: 8.2888 - val_accuracy: 0.4365\n",
      "Epoch 239/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0602 - accuracy: 0.9842 - val_loss: 7.8411 - val_accuracy: 0.4688\n",
      "Epoch 240/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0675 - accuracy: 0.9822 - val_loss: 7.6113 - val_accuracy: 0.4518\n",
      "Epoch 241/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0519 - accuracy: 0.9848 - val_loss: 8.6650 - val_accuracy: 0.4316\n",
      "Epoch 242/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0550 - accuracy: 0.9854 - val_loss: 10.0750 - val_accuracy: 0.3709\n",
      "Epoch 243/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0594 - accuracy: 0.9844 - val_loss: 8.6088 - val_accuracy: 0.4539\n",
      "Epoch 244/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0470 - accuracy: 0.9862 - val_loss: 8.5993 - val_accuracy: 0.4599\n",
      "Epoch 245/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0525 - accuracy: 0.9858 - val_loss: 8.6012 - val_accuracy: 0.4468\n",
      "Epoch 246/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0706 - accuracy: 0.9823 - val_loss: 7.8988 - val_accuracy: 0.4684\n",
      "Epoch 247/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0540 - accuracy: 0.9853 - val_loss: 7.8152 - val_accuracy: 0.4594\n",
      "Epoch 248/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0527 - accuracy: 0.9854 - val_loss: 8.8864 - val_accuracy: 0.4439\n",
      "Epoch 249/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0764 - accuracy: 0.9818 - val_loss: 8.3958 - val_accuracy: 0.4536\n",
      "Epoch 250/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0477 - accuracy: 0.9868 - val_loss: 8.7187 - val_accuracy: 0.4566\n",
      "Epoch 251/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0712 - accuracy: 0.9832 - val_loss: 8.9192 - val_accuracy: 0.4632\n",
      "Epoch 252/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0829 - accuracy: 0.9804 - val_loss: 9.2545 - val_accuracy: 0.4365\n",
      "Epoch 253/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0565 - accuracy: 0.9835 - val_loss: 9.7817 - val_accuracy: 0.4391\n",
      "Epoch 254/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0793 - accuracy: 0.9810 - val_loss: 9.1901 - val_accuracy: 0.4577\n",
      "Epoch 255/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0796 - accuracy: 0.9800 - val_loss: 9.6670 - val_accuracy: 0.4120\n",
      "Epoch 256/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0826 - accuracy: 0.9811 - val_loss: 9.1232 - val_accuracy: 0.4200\n",
      "Epoch 257/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0763 - accuracy: 0.9809 - val_loss: 9.1648 - val_accuracy: 0.4440\n",
      "Epoch 258/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0738 - accuracy: 0.9819 - val_loss: 8.9855 - val_accuracy: 0.4463\n",
      "Epoch 259/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0673 - accuracy: 0.9824 - val_loss: 9.3924 - val_accuracy: 0.4450\n",
      "Epoch 260/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0642 - accuracy: 0.9829 - val_loss: 9.2127 - val_accuracy: 0.4420\n",
      "Epoch 261/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0664 - accuracy: 0.9828 - val_loss: 8.9922 - val_accuracy: 0.4436\n",
      "Epoch 262/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0671 - accuracy: 0.9818 - val_loss: 10.6913 - val_accuracy: 0.3805\n",
      "Epoch 263/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0633 - accuracy: 0.9833 - val_loss: 8.9844 - val_accuracy: 0.4367\n",
      "Epoch 264/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0569 - accuracy: 0.9854 - val_loss: 8.6784 - val_accuracy: 0.4586\n",
      "Epoch 265/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0482 - accuracy: 0.9868 - val_loss: 9.4021 - val_accuracy: 0.4436\n",
      "Epoch 266/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0586 - accuracy: 0.9851 - val_loss: 8.6622 - val_accuracy: 0.4738\n",
      "Epoch 267/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0593 - accuracy: 0.9838 - val_loss: 8.6577 - val_accuracy: 0.4367\n",
      "Epoch 268/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0483 - accuracy: 0.9870 - val_loss: 8.7711 - val_accuracy: 0.4404\n",
      "Epoch 269/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0421 - accuracy: 0.9888 - val_loss: 8.2702 - val_accuracy: 0.4840\n",
      "Epoch 270/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0498 - accuracy: 0.9854 - val_loss: 8.5302 - val_accuracy: 0.4500\n",
      "Epoch 271/15000\n",
      "1024/1024 [==============================] - 15s 15ms/step - loss: 0.0459 - accuracy: 0.9879 - val_loss: 8.8358 - val_accuracy: 0.4461\n",
      "Epoch 272/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0464 - accuracy: 0.9867 - val_loss: 9.5615 - val_accuracy: 0.4449\n",
      "Epoch 273/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0518 - accuracy: 0.9867 - val_loss: 8.6236 - val_accuracy: 0.4658\n",
      "Epoch 274/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0515 - accuracy: 0.9865 - val_loss: 9.4543 - val_accuracy: 0.3848\n",
      "Epoch 275/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0366 - accuracy: 0.9898 - val_loss: 8.5238 - val_accuracy: 0.4674\n",
      "Epoch 276/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0641 - accuracy: 0.9846 - val_loss: 9.0666 - val_accuracy: 0.4571\n",
      "Epoch 277/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0477 - accuracy: 0.9866 - val_loss: 9.2709 - val_accuracy: 0.4516\n",
      "Epoch 278/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0590 - accuracy: 0.9853 - val_loss: 9.5191 - val_accuracy: 0.4634\n",
      "Epoch 279/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0636 - accuracy: 0.9844 - val_loss: 9.1062 - val_accuracy: 0.4676\n",
      "Epoch 280/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0714 - accuracy: 0.9828 - val_loss: 10.4412 - val_accuracy: 0.4250\n",
      "Epoch 281/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0643 - accuracy: 0.9850 - val_loss: 9.6923 - val_accuracy: 0.4448\n",
      "Epoch 282/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0658 - accuracy: 0.9843 - val_loss: 9.5302 - val_accuracy: 0.4519\n",
      "Epoch 283/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0629 - accuracy: 0.9846 - val_loss: 9.9343 - val_accuracy: 0.4333\n",
      "Epoch 284/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0666 - accuracy: 0.9834 - val_loss: 9.8713 - val_accuracy: 0.4482\n",
      "Epoch 285/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0617 - accuracy: 0.9858 - val_loss: 10.0743 - val_accuracy: 0.4500\n",
      "Epoch 286/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0622 - accuracy: 0.9851 - val_loss: 9.8420 - val_accuracy: 0.4599\n",
      "Epoch 287/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0623 - accuracy: 0.9849 - val_loss: 9.5413 - val_accuracy: 0.4583\n",
      "Epoch 288/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0616 - accuracy: 0.9851 - val_loss: 9.7660 - val_accuracy: 0.4525\n",
      "Epoch 289/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0635 - accuracy: 0.9839 - val_loss: 10.2088 - val_accuracy: 0.4290\n",
      "Epoch 290/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0560 - accuracy: 0.9849 - val_loss: 9.5048 - val_accuracy: 0.4382\n",
      "Epoch 291/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0562 - accuracy: 0.9859 - val_loss: 9.0489 - val_accuracy: 0.4699\n",
      "Epoch 292/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0445 - accuracy: 0.9885 - val_loss: 8.8251 - val_accuracy: 0.4620\n",
      "Epoch 293/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0551 - accuracy: 0.9865 - val_loss: 8.7544 - val_accuracy: 0.4677\n",
      "Epoch 294/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0459 - accuracy: 0.9881 - val_loss: 9.5591 - val_accuracy: 0.4442\n",
      "Epoch 295/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0472 - accuracy: 0.9873 - val_loss: 9.1941 - val_accuracy: 0.4534\n",
      "Epoch 296/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0412 - accuracy: 0.9892 - val_loss: 9.0266 - val_accuracy: 0.4745\n",
      "Epoch 297/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0450 - accuracy: 0.9885 - val_loss: 9.3638 - val_accuracy: 0.4431\n",
      "Epoch 298/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0441 - accuracy: 0.9883 - val_loss: 10.2479 - val_accuracy: 0.4152\n",
      "Epoch 299/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0416 - accuracy: 0.9886 - val_loss: 9.5748 - val_accuracy: 0.4419\n",
      "Epoch 300/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0486 - accuracy: 0.9884 - val_loss: 9.8367 - val_accuracy: 0.4422\n",
      "Epoch 301/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0426 - accuracy: 0.9885 - val_loss: 9.9485 - val_accuracy: 0.4463\n",
      "Epoch 302/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0420 - accuracy: 0.9895 - val_loss: 9.7024 - val_accuracy: 0.4270\n",
      "Epoch 303/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0394 - accuracy: 0.9901 - val_loss: 9.9572 - val_accuracy: 0.4430\n",
      "Epoch 304/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0541 - accuracy: 0.9872 - val_loss: 9.6418 - val_accuracy: 0.4632\n",
      "Epoch 305/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0445 - accuracy: 0.9884 - val_loss: 9.5853 - val_accuracy: 0.4676\n",
      "Epoch 306/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0479 - accuracy: 0.9879 - val_loss: 9.9945 - val_accuracy: 0.4532\n",
      "Epoch 307/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0608 - accuracy: 0.9859 - val_loss: 10.4811 - val_accuracy: 0.4438\n",
      "Epoch 308/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0506 - accuracy: 0.9867 - val_loss: 10.6938 - val_accuracy: 0.4512\n",
      "Epoch 309/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0605 - accuracy: 0.9857 - val_loss: 10.7801 - val_accuracy: 0.4263\n",
      "Epoch 310/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0596 - accuracy: 0.9846 - val_loss: 10.0590 - val_accuracy: 0.4613\n",
      "Epoch 311/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0530 - accuracy: 0.9865 - val_loss: 10.5453 - val_accuracy: 0.4362\n",
      "Epoch 312/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0574 - accuracy: 0.9868 - val_loss: 10.2188 - val_accuracy: 0.4585\n",
      "Epoch 313/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0542 - accuracy: 0.9877 - val_loss: 10.0551 - val_accuracy: 0.4562\n",
      "Epoch 314/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0563 - accuracy: 0.9864 - val_loss: 10.8434 - val_accuracy: 0.4318\n",
      "Epoch 315/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0530 - accuracy: 0.9868 - val_loss: 10.1015 - val_accuracy: 0.4501\n",
      "Epoch 316/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0617 - accuracy: 0.9851 - val_loss: 10.7731 - val_accuracy: 0.4011\n",
      "Epoch 317/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0538 - accuracy: 0.9865 - val_loss: 9.8027 - val_accuracy: 0.4573\n",
      "Epoch 318/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0502 - accuracy: 0.9870 - val_loss: 10.4433 - val_accuracy: 0.4339\n",
      "Epoch 319/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0509 - accuracy: 0.9886 - val_loss: 9.4891 - val_accuracy: 0.4704\n",
      "Epoch 320/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0382 - accuracy: 0.9899 - val_loss: 9.4001 - val_accuracy: 0.4710\n",
      "Epoch 321/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0481 - accuracy: 0.9893 - val_loss: 10.3302 - val_accuracy: 0.4572\n",
      "Epoch 322/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0442 - accuracy: 0.9885 - val_loss: 9.6437 - val_accuracy: 0.4424\n",
      "Epoch 323/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0377 - accuracy: 0.9902 - val_loss: 10.1164 - val_accuracy: 0.4504\n",
      "Epoch 324/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0336 - accuracy: 0.9916 - val_loss: 9.7942 - val_accuracy: 0.4487\n",
      "Epoch 325/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0382 - accuracy: 0.9893 - val_loss: 9.9529 - val_accuracy: 0.4613\n",
      "Epoch 326/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0315 - accuracy: 0.9909 - val_loss: 11.8210 - val_accuracy: 0.3918\n",
      "Epoch 327/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0452 - accuracy: 0.9890 - val_loss: 9.7381 - val_accuracy: 0.4652\n",
      "Epoch 328/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0461 - accuracy: 0.9885 - val_loss: 10.0981 - val_accuracy: 0.4492\n",
      "Epoch 329/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0346 - accuracy: 0.9908 - val_loss: 9.7676 - val_accuracy: 0.4576\n",
      "Epoch 330/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0315 - accuracy: 0.9914 - val_loss: 10.0640 - val_accuracy: 0.4687\n",
      "Epoch 331/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0525 - accuracy: 0.9882 - val_loss: 10.4197 - val_accuracy: 0.4602\n",
      "Epoch 332/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0396 - accuracy: 0.9896 - val_loss: 10.6474 - val_accuracy: 0.4636\n",
      "Epoch 333/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0430 - accuracy: 0.9898 - val_loss: 10.7603 - val_accuracy: 0.4581\n",
      "Epoch 334/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0508 - accuracy: 0.9880 - val_loss: 11.1544 - val_accuracy: 0.4255\n",
      "Epoch 335/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0454 - accuracy: 0.9885 - val_loss: 11.2792 - val_accuracy: 0.4539\n",
      "Epoch 336/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0496 - accuracy: 0.9890 - val_loss: 10.6223 - val_accuracy: 0.4407\n",
      "Epoch 337/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0512 - accuracy: 0.9880 - val_loss: 10.8658 - val_accuracy: 0.4411\n",
      "Epoch 338/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0513 - accuracy: 0.9880 - val_loss: 11.3794 - val_accuracy: 0.4375\n",
      "Epoch 339/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0521 - accuracy: 0.9877 - val_loss: 10.7718 - val_accuracy: 0.4473\n",
      "Epoch 340/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0459 - accuracy: 0.9899 - val_loss: 11.4454 - val_accuracy: 0.4620\n",
      "Epoch 341/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0502 - accuracy: 0.9886 - val_loss: 10.9975 - val_accuracy: 0.4460\n",
      "Epoch 342/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0510 - accuracy: 0.9878 - val_loss: 11.4882 - val_accuracy: 0.4364\n",
      "Epoch 343/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0493 - accuracy: 0.9883 - val_loss: 11.1251 - val_accuracy: 0.4460\n",
      "Epoch 344/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0518 - accuracy: 0.9879 - val_loss: 11.1194 - val_accuracy: 0.4250\n",
      "Epoch 345/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0449 - accuracy: 0.9893 - val_loss: 10.5577 - val_accuracy: 0.4474\n",
      "Epoch 346/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0451 - accuracy: 0.9893 - val_loss: 10.7945 - val_accuracy: 0.4486\n",
      "Epoch 347/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0387 - accuracy: 0.9911 - val_loss: 10.7888 - val_accuracy: 0.4511\n",
      "Epoch 348/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0389 - accuracy: 0.9907 - val_loss: 10.3244 - val_accuracy: 0.4647\n",
      "Epoch 349/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0390 - accuracy: 0.9902 - val_loss: 9.9164 - val_accuracy: 0.4580\n",
      "Epoch 350/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0415 - accuracy: 0.9895 - val_loss: 11.1244 - val_accuracy: 0.4408\n",
      "Epoch 351/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0289 - accuracy: 0.9921 - val_loss: 10.2379 - val_accuracy: 0.4748\n",
      "Epoch 352/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0397 - accuracy: 0.9897 - val_loss: 11.2130 - val_accuracy: 0.4397\n",
      "Epoch 353/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0405 - accuracy: 0.9902 - val_loss: 10.7107 - val_accuracy: 0.4396\n",
      "Epoch 354/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0337 - accuracy: 0.9918 - val_loss: 10.9088 - val_accuracy: 0.4590\n",
      "Epoch 355/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0443 - accuracy: 0.9905 - val_loss: 10.4603 - val_accuracy: 0.4536\n",
      "Epoch 356/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0327 - accuracy: 0.9911 - val_loss: 10.5185 - val_accuracy: 0.4657\n",
      "Epoch 357/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0309 - accuracy: 0.9926 - val_loss: 10.2632 - val_accuracy: 0.4690\n",
      "Epoch 358/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0421 - accuracy: 0.9909 - val_loss: 10.8152 - val_accuracy: 0.4638\n",
      "Epoch 359/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0494 - accuracy: 0.9893 - val_loss: 11.3937 - val_accuracy: 0.4618\n",
      "Epoch 360/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0395 - accuracy: 0.9910 - val_loss: 10.7901 - val_accuracy: 0.4686\n",
      "Epoch 361/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0467 - accuracy: 0.9897 - val_loss: 12.4637 - val_accuracy: 0.4198\n",
      "Epoch 362/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0511 - accuracy: 0.9882 - val_loss: 11.6476 - val_accuracy: 0.4425\n",
      "Epoch 363/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0360 - accuracy: 0.9916 - val_loss: 12.0867 - val_accuracy: 0.4544\n",
      "Epoch 364/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0440 - accuracy: 0.9897 - val_loss: 11.2461 - val_accuracy: 0.4666\n",
      "Epoch 365/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0553 - accuracy: 0.9880 - val_loss: 12.0434 - val_accuracy: 0.4495\n",
      "Epoch 366/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0464 - accuracy: 0.9892 - val_loss: 12.2195 - val_accuracy: 0.4291\n",
      "Epoch 367/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0558 - accuracy: 0.9883 - val_loss: 11.4729 - val_accuracy: 0.4459\n",
      "Epoch 368/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0447 - accuracy: 0.9896 - val_loss: 11.0919 - val_accuracy: 0.4758\n",
      "Epoch 369/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0417 - accuracy: 0.9899 - val_loss: 11.5701 - val_accuracy: 0.4450\n",
      "Epoch 370/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0482 - accuracy: 0.9895 - val_loss: 12.2834 - val_accuracy: 0.4303\n",
      "Epoch 371/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0397 - accuracy: 0.9902 - val_loss: 11.9644 - val_accuracy: 0.4539\n",
      "Epoch 372/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0420 - accuracy: 0.9893 - val_loss: 11.8591 - val_accuracy: 0.4306\n",
      "Epoch 373/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0460 - accuracy: 0.9893 - val_loss: 11.1259 - val_accuracy: 0.4587\n",
      "Epoch 374/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0424 - accuracy: 0.9905 - val_loss: 10.7473 - val_accuracy: 0.4580\n",
      "Epoch 375/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0445 - accuracy: 0.9904 - val_loss: 10.6996 - val_accuracy: 0.4628\n",
      "Epoch 376/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0387 - accuracy: 0.9908 - val_loss: 10.5530 - val_accuracy: 0.4735\n",
      "Epoch 377/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0371 - accuracy: 0.9914 - val_loss: 11.0276 - val_accuracy: 0.4528\n",
      "Epoch 378/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0312 - accuracy: 0.9925 - val_loss: 11.2693 - val_accuracy: 0.4421\n",
      "Epoch 379/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0318 - accuracy: 0.9922 - val_loss: 12.1718 - val_accuracy: 0.4261\n",
      "Epoch 380/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0407 - accuracy: 0.9910 - val_loss: 11.5917 - val_accuracy: 0.4606\n",
      "Epoch 381/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0324 - accuracy: 0.9915 - val_loss: 11.5015 - val_accuracy: 0.4562\n",
      "Epoch 382/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0361 - accuracy: 0.9910 - val_loss: 11.3932 - val_accuracy: 0.4560\n",
      "Epoch 383/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0363 - accuracy: 0.9914 - val_loss: 10.6160 - val_accuracy: 0.4677\n",
      "Epoch 384/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0318 - accuracy: 0.9920 - val_loss: 11.0283 - val_accuracy: 0.4622\n",
      "Epoch 385/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0294 - accuracy: 0.9924 - val_loss: 11.9126 - val_accuracy: 0.4543\n",
      "Epoch 386/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0503 - accuracy: 0.9895 - val_loss: 11.6306 - val_accuracy: 0.4604\n",
      "Epoch 387/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0352 - accuracy: 0.9911 - val_loss: 11.9323 - val_accuracy: 0.4731\n",
      "Epoch 388/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0393 - accuracy: 0.9912 - val_loss: 12.2358 - val_accuracy: 0.4529\n",
      "Epoch 389/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0472 - accuracy: 0.9893 - val_loss: 12.5385 - val_accuracy: 0.4442\n",
      "Epoch 390/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0446 - accuracy: 0.9902 - val_loss: 12.2648 - val_accuracy: 0.4574\n",
      "Epoch 391/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0487 - accuracy: 0.9898 - val_loss: 12.2592 - val_accuracy: 0.4573\n",
      "Epoch 392/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0506 - accuracy: 0.9880 - val_loss: 12.9269 - val_accuracy: 0.4335\n",
      "Epoch 393/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0453 - accuracy: 0.9901 - val_loss: 12.4987 - val_accuracy: 0.4326\n",
      "Epoch 394/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0493 - accuracy: 0.9897 - val_loss: 11.5136 - val_accuracy: 0.4561\n",
      "Epoch 395/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0472 - accuracy: 0.9909 - val_loss: 12.0454 - val_accuracy: 0.4587\n",
      "Epoch 396/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0431 - accuracy: 0.9897 - val_loss: 12.2588 - val_accuracy: 0.4590\n",
      "Epoch 397/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0436 - accuracy: 0.9893 - val_loss: 13.3536 - val_accuracy: 0.4312\n",
      "Epoch 398/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0413 - accuracy: 0.9912 - val_loss: 12.0506 - val_accuracy: 0.4471\n",
      "Epoch 399/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0399 - accuracy: 0.9896 - val_loss: 14.3402 - val_accuracy: 0.3962\n",
      "Epoch 400/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0372 - accuracy: 0.9913 - val_loss: 12.3393 - val_accuracy: 0.4490\n",
      "Epoch 401/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0446 - accuracy: 0.9903 - val_loss: 11.4286 - val_accuracy: 0.4686\n",
      "Epoch 402/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0372 - accuracy: 0.9911 - val_loss: 11.7813 - val_accuracy: 0.4696\n",
      "Epoch 403/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0390 - accuracy: 0.9917 - val_loss: 11.6555 - val_accuracy: 0.4650\n",
      "Epoch 404/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0427 - accuracy: 0.9908 - val_loss: 11.5557 - val_accuracy: 0.4568\n",
      "Epoch 405/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0309 - accuracy: 0.9927 - val_loss: 12.2341 - val_accuracy: 0.4410\n",
      "Epoch 406/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0253 - accuracy: 0.9940 - val_loss: 11.4205 - val_accuracy: 0.4837\n",
      "Epoch 407/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0340 - accuracy: 0.9920 - val_loss: 12.1797 - val_accuracy: 0.4437\n",
      "Epoch 408/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0313 - accuracy: 0.9922 - val_loss: 12.0032 - val_accuracy: 0.4551\n",
      "Epoch 409/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0341 - accuracy: 0.9921 - val_loss: 11.5285 - val_accuracy: 0.4704\n",
      "Epoch 410/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0323 - accuracy: 0.9923 - val_loss: 12.0361 - val_accuracy: 0.4657\n",
      "Epoch 411/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0357 - accuracy: 0.9918 - val_loss: 12.3568 - val_accuracy: 0.4272\n",
      "Epoch 412/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0260 - accuracy: 0.9934 - val_loss: 11.2950 - val_accuracy: 0.4771\n",
      "Epoch 413/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0471 - accuracy: 0.9899 - val_loss: 12.0664 - val_accuracy: 0.4671\n",
      "Epoch 414/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0301 - accuracy: 0.9929 - val_loss: 12.8081 - val_accuracy: 0.4509\n",
      "Epoch 415/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0367 - accuracy: 0.9923 - val_loss: 12.3591 - val_accuracy: 0.4793\n",
      "Epoch 416/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0472 - accuracy: 0.9904 - val_loss: 12.8152 - val_accuracy: 0.4670\n",
      "Epoch 417/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0470 - accuracy: 0.9900 - val_loss: 13.6169 - val_accuracy: 0.4432\n",
      "Epoch 418/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0459 - accuracy: 0.9903 - val_loss: 13.8719 - val_accuracy: 0.4313\n",
      "Epoch 419/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0436 - accuracy: 0.9915 - val_loss: 13.1307 - val_accuracy: 0.4476\n",
      "Epoch 420/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0485 - accuracy: 0.9899 - val_loss: 13.8503 - val_accuracy: 0.4359\n",
      "Epoch 421/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0442 - accuracy: 0.9904 - val_loss: 14.1885 - val_accuracy: 0.4274\n",
      "Epoch 422/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0459 - accuracy: 0.9913 - val_loss: 13.9012 - val_accuracy: 0.4514\n",
      "Epoch 423/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0342 - accuracy: 0.9914 - val_loss: 13.4964 - val_accuracy: 0.4554\n",
      "Epoch 424/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0448 - accuracy: 0.9903 - val_loss: 13.0226 - val_accuracy: 0.4624\n",
      "Epoch 425/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0412 - accuracy: 0.9910 - val_loss: 13.2502 - val_accuracy: 0.4531\n",
      "Epoch 426/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0491 - accuracy: 0.9896 - val_loss: 14.1116 - val_accuracy: 0.4147\n",
      "Epoch 427/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0446 - accuracy: 0.9897 - val_loss: 12.6557 - val_accuracy: 0.4512\n",
      "Epoch 428/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0392 - accuracy: 0.9914 - val_loss: 12.3244 - val_accuracy: 0.4671\n",
      "Epoch 429/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0326 - accuracy: 0.9921 - val_loss: 12.5193 - val_accuracy: 0.4576\n",
      "Epoch 430/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0411 - accuracy: 0.9915 - val_loss: 11.9474 - val_accuracy: 0.4660\n",
      "Epoch 431/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0359 - accuracy: 0.9917 - val_loss: 12.7332 - val_accuracy: 0.4418\n",
      "Epoch 432/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0306 - accuracy: 0.9927 - val_loss: 12.5562 - val_accuracy: 0.4486\n",
      "Epoch 433/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0320 - accuracy: 0.9934 - val_loss: 12.2833 - val_accuracy: 0.4677\n",
      "Epoch 434/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0305 - accuracy: 0.9922 - val_loss: 12.6554 - val_accuracy: 0.4450\n",
      "Epoch 435/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0426 - accuracy: 0.9913 - val_loss: 13.1180 - val_accuracy: 0.4461\n",
      "Epoch 436/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0276 - accuracy: 0.9935 - val_loss: 12.4766 - val_accuracy: 0.4590\n",
      "Epoch 437/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0303 - accuracy: 0.9929 - val_loss: 12.4948 - val_accuracy: 0.4641\n",
      "Epoch 438/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0297 - accuracy: 0.9929 - val_loss: 12.6412 - val_accuracy: 0.4663\n",
      "Epoch 439/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0325 - accuracy: 0.9922 - val_loss: 12.9089 - val_accuracy: 0.4378\n",
      "Epoch 440/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0251 - accuracy: 0.9941 - val_loss: 12.9486 - val_accuracy: 0.4531\n",
      "Epoch 441/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0431 - accuracy: 0.9914 - val_loss: 13.7725 - val_accuracy: 0.4356\n",
      "Epoch 442/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0313 - accuracy: 0.9926 - val_loss: 13.4135 - val_accuracy: 0.4638\n",
      "Epoch 443/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0312 - accuracy: 0.9930 - val_loss: 14.0175 - val_accuracy: 0.4497\n",
      "Epoch 444/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0488 - accuracy: 0.9905 - val_loss: 13.9361 - val_accuracy: 0.4484\n",
      "Epoch 445/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0385 - accuracy: 0.9918 - val_loss: 13.9804 - val_accuracy: 0.4523\n",
      "Epoch 446/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0479 - accuracy: 0.9906 - val_loss: 14.6148 - val_accuracy: 0.4407\n",
      "Epoch 447/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0440 - accuracy: 0.9901 - val_loss: 13.7615 - val_accuracy: 0.4672\n",
      "Epoch 448/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0442 - accuracy: 0.9905 - val_loss: 14.2586 - val_accuracy: 0.4378\n",
      "Epoch 449/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0430 - accuracy: 0.9916 - val_loss: 13.7637 - val_accuracy: 0.4568\n",
      "Epoch 450/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0490 - accuracy: 0.9908 - val_loss: 13.5777 - val_accuracy: 0.4580\n",
      "Epoch 451/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0408 - accuracy: 0.9913 - val_loss: 14.6816 - val_accuracy: 0.4296\n",
      "Epoch 452/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0493 - accuracy: 0.9908 - val_loss: 14.0746 - val_accuracy: 0.4465\n",
      "Epoch 453/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0417 - accuracy: 0.9912 - val_loss: 14.7239 - val_accuracy: 0.4191\n",
      "Epoch 454/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0387 - accuracy: 0.9915 - val_loss: 13.8568 - val_accuracy: 0.4420\n",
      "Epoch 455/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0388 - accuracy: 0.9911 - val_loss: 13.5243 - val_accuracy: 0.4485\n",
      "Epoch 456/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0374 - accuracy: 0.9927 - val_loss: 13.0569 - val_accuracy: 0.4545\n",
      "Epoch 457/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0375 - accuracy: 0.9925 - val_loss: 12.8370 - val_accuracy: 0.4661\n",
      "Epoch 458/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0303 - accuracy: 0.9935 - val_loss: 13.3892 - val_accuracy: 0.4695\n",
      "Epoch 459/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0382 - accuracy: 0.9916 - val_loss: 13.1683 - val_accuracy: 0.4394\n",
      "Epoch 460/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0302 - accuracy: 0.9931 - val_loss: 13.6864 - val_accuracy: 0.4465\n",
      "Epoch 461/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0328 - accuracy: 0.9928 - val_loss: 14.0726 - val_accuracy: 0.4328\n",
      "Epoch 462/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0310 - accuracy: 0.9933 - val_loss: 13.1854 - val_accuracy: 0.4517\n",
      "Epoch 463/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0274 - accuracy: 0.9934 - val_loss: 16.1638 - val_accuracy: 0.3899\n",
      "Epoch 464/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0329 - accuracy: 0.9928 - val_loss: 13.5249 - val_accuracy: 0.4592\n",
      "Epoch 465/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0349 - accuracy: 0.9930 - val_loss: 13.0603 - val_accuracy: 0.4622\n",
      "Epoch 466/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0310 - accuracy: 0.9931 - val_loss: 12.7387 - val_accuracy: 0.4704\n",
      "Epoch 467/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0238 - accuracy: 0.9945 - val_loss: 13.2629 - val_accuracy: 0.4720\n",
      "Epoch 468/15000\n",
      "1024/1024 [==============================] - 17s 16ms/step - loss: 0.0487 - accuracy: 0.9907 - val_loss: 13.6307 - val_accuracy: 0.4638\n",
      "Epoch 469/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0256 - accuracy: 0.9940 - val_loss: 13.7774 - val_accuracy: 0.4598\n",
      "Epoch 470/15000\n",
      "1024/1024 [==============================] - 15s 14ms/step - loss: 0.0344 - accuracy: 0.9927 - val_loss: 14.1090 - val_accuracy: 0.4637\n",
      "Epoch 471/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0429 - accuracy: 0.9913 - val_loss: 14.6510 - val_accuracy: 0.4262\n",
      "Epoch 472/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0367 - accuracy: 0.9921 - val_loss: 14.7256 - val_accuracy: 0.4454\n",
      "Epoch 473/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0402 - accuracy: 0.9919 - val_loss: 14.3580 - val_accuracy: 0.4489\n",
      "Epoch 474/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0415 - accuracy: 0.9916 - val_loss: 15.0573 - val_accuracy: 0.4399\n",
      "Epoch 475/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0502 - accuracy: 0.9910 - val_loss: 14.6237 - val_accuracy: 0.4421\n",
      "Epoch 476/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0369 - accuracy: 0.9925 - val_loss: 14.8759 - val_accuracy: 0.4548\n",
      "Epoch 477/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0354 - accuracy: 0.9932 - val_loss: 14.7185 - val_accuracy: 0.4623\n",
      "Epoch 478/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0368 - accuracy: 0.9929 - val_loss: 14.7507 - val_accuracy: 0.4485\n",
      "Epoch 479/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0399 - accuracy: 0.9919 - val_loss: 14.8650 - val_accuracy: 0.4460\n",
      "Epoch 480/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0336 - accuracy: 0.9927 - val_loss: 14.9076 - val_accuracy: 0.4510\n",
      "Epoch 481/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0454 - accuracy: 0.9911 - val_loss: 15.5468 - val_accuracy: 0.4210\n",
      "Epoch 482/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0383 - accuracy: 0.9913 - val_loss: 14.8640 - val_accuracy: 0.4383\n",
      "Epoch 483/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0391 - accuracy: 0.9929 - val_loss: 14.6067 - val_accuracy: 0.4469\n",
      "Epoch 484/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0289 - accuracy: 0.9941 - val_loss: 13.9397 - val_accuracy: 0.4578\n",
      "Epoch 485/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0326 - accuracy: 0.9936 - val_loss: 13.6668 - val_accuracy: 0.4688\n",
      "Epoch 486/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0352 - accuracy: 0.9920 - val_loss: 14.0378 - val_accuracy: 0.4499\n",
      "Epoch 487/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0258 - accuracy: 0.9942 - val_loss: 15.2463 - val_accuracy: 0.4353\n",
      "Epoch 488/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0236 - accuracy: 0.9949 - val_loss: 13.7063 - val_accuracy: 0.4688\n",
      "Epoch 489/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0330 - accuracy: 0.9931 - val_loss: 14.6813 - val_accuracy: 0.4478\n",
      "Epoch 490/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0319 - accuracy: 0.9931 - val_loss: 14.8181 - val_accuracy: 0.4303\n",
      "Epoch 491/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0268 - accuracy: 0.9939 - val_loss: 14.1190 - val_accuracy: 0.4511\n",
      "Epoch 492/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0313 - accuracy: 0.9939 - val_loss: 13.8636 - val_accuracy: 0.4531\n",
      "Epoch 493/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0245 - accuracy: 0.9946 - val_loss: 13.9750 - val_accuracy: 0.4646\n",
      "Epoch 494/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0293 - accuracy: 0.9936 - val_loss: 14.5171 - val_accuracy: 0.4550\n",
      "Epoch 495/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0287 - accuracy: 0.9942 - val_loss: 14.5121 - val_accuracy: 0.4515\n",
      "Epoch 496/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0381 - accuracy: 0.9925 - val_loss: 14.8142 - val_accuracy: 0.4596\n",
      "Epoch 497/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0333 - accuracy: 0.9931 - val_loss: 14.4099 - val_accuracy: 0.4722\n",
      "Epoch 498/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0364 - accuracy: 0.9928 - val_loss: 15.9274 - val_accuracy: 0.4475\n",
      "Epoch 499/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0402 - accuracy: 0.9919 - val_loss: 15.5652 - val_accuracy: 0.4439\n",
      "Epoch 500/15000\n",
      "1023/1024 [============================>.] - ETA: 0s - loss: 0.0354 - accuracy: 0.9932\n",
      "Epoch 500: saving model to ./checkpoints\\cn_ocr-500.ckpt\n",
      "1024/1024 [==============================] - 15s 15ms/step - loss: 0.0358 - accuracy: 0.9931 - val_loss: 15.7270 - val_accuracy: 0.4605\n",
      "Epoch 501/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0467 - accuracy: 0.9922 - val_loss: 15.3090 - val_accuracy: 0.4661\n",
      "Epoch 502/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0507 - accuracy: 0.9912 - val_loss: 15.5183 - val_accuracy: 0.4514\n",
      "Epoch 503/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0444 - accuracy: 0.9922 - val_loss: 15.5007 - val_accuracy: 0.4363\n",
      "Epoch 504/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0426 - accuracy: 0.9925 - val_loss: 14.9747 - val_accuracy: 0.4597\n",
      "Epoch 505/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0405 - accuracy: 0.9926 - val_loss: 14.7952 - val_accuracy: 0.4663\n",
      "Epoch 506/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0428 - accuracy: 0.9915 - val_loss: 15.3513 - val_accuracy: 0.4467\n",
      "Epoch 507/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0368 - accuracy: 0.9928 - val_loss: 15.5443 - val_accuracy: 0.4487\n",
      "Epoch 508/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0385 - accuracy: 0.9933 - val_loss: 16.2911 - val_accuracy: 0.4416\n",
      "Epoch 509/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0355 - accuracy: 0.9922 - val_loss: 16.3034 - val_accuracy: 0.4286\n",
      "Epoch 510/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0365 - accuracy: 0.9928 - val_loss: 15.0249 - val_accuracy: 0.4587\n",
      "Epoch 511/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0355 - accuracy: 0.9933 - val_loss: 14.2663 - val_accuracy: 0.4635\n",
      "Epoch 512/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0254 - accuracy: 0.9940 - val_loss: 14.5000 - val_accuracy: 0.4625\n",
      "Epoch 513/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0356 - accuracy: 0.9931 - val_loss: 14.1637 - val_accuracy: 0.4692\n",
      "Epoch 514/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0321 - accuracy: 0.9934 - val_loss: 14.1268 - val_accuracy: 0.4502\n",
      "Epoch 515/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0253 - accuracy: 0.9943 - val_loss: 14.9144 - val_accuracy: 0.4461\n",
      "Epoch 516/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0339 - accuracy: 0.9933 - val_loss: 16.2607 - val_accuracy: 0.4320\n",
      "Epoch 517/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0327 - accuracy: 0.9935 - val_loss: 14.6938 - val_accuracy: 0.4636\n",
      "Epoch 518/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0249 - accuracy: 0.9940 - val_loss: 14.9804 - val_accuracy: 0.4543\n",
      "Epoch 519/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0294 - accuracy: 0.9941 - val_loss: 15.3712 - val_accuracy: 0.4525\n",
      "Epoch 520/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0279 - accuracy: 0.9937 - val_loss: 14.1573 - val_accuracy: 0.4605\n",
      "Epoch 521/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0287 - accuracy: 0.9942 - val_loss: 15.0907 - val_accuracy: 0.4537\n",
      "Epoch 522/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0288 - accuracy: 0.9945 - val_loss: 14.8138 - val_accuracy: 0.4601\n",
      "Epoch 523/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0365 - accuracy: 0.9929 - val_loss: 15.1306 - val_accuracy: 0.4694\n",
      "Epoch 524/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0318 - accuracy: 0.9935 - val_loss: 16.0823 - val_accuracy: 0.4574\n",
      "Epoch 525/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0328 - accuracy: 0.9934 - val_loss: 15.3937 - val_accuracy: 0.4675\n",
      "Epoch 526/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0484 - accuracy: 0.9911 - val_loss: 16.4643 - val_accuracy: 0.4437\n",
      "Epoch 527/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0277 - accuracy: 0.9944 - val_loss: 16.1566 - val_accuracy: 0.4526\n",
      "Epoch 528/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0410 - accuracy: 0.9927 - val_loss: 15.8644 - val_accuracy: 0.4565\n",
      "Epoch 529/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0487 - accuracy: 0.9916 - val_loss: 16.0594 - val_accuracy: 0.4411\n",
      "Epoch 530/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0388 - accuracy: 0.9926 - val_loss: 16.3960 - val_accuracy: 0.4413\n",
      "Epoch 531/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0360 - accuracy: 0.9932 - val_loss: 15.6607 - val_accuracy: 0.4563\n",
      "Epoch 532/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0374 - accuracy: 0.9934 - val_loss: 15.2804 - val_accuracy: 0.4676\n",
      "Epoch 533/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0330 - accuracy: 0.9933 - val_loss: 16.4003 - val_accuracy: 0.4645\n",
      "Epoch 534/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0326 - accuracy: 0.9929 - val_loss: 16.3089 - val_accuracy: 0.4526\n",
      "Epoch 535/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0390 - accuracy: 0.9929 - val_loss: 16.3789 - val_accuracy: 0.4530\n",
      "Epoch 536/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0347 - accuracy: 0.9929 - val_loss: 17.2075 - val_accuracy: 0.4262\n",
      "Epoch 537/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0335 - accuracy: 0.9930 - val_loss: 15.7990 - val_accuracy: 0.4481\n",
      "Epoch 538/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0395 - accuracy: 0.9933 - val_loss: 15.2702 - val_accuracy: 0.4664\n",
      "Epoch 539/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0297 - accuracy: 0.9942 - val_loss: 15.4794 - val_accuracy: 0.4689\n",
      "Epoch 540/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0325 - accuracy: 0.9937 - val_loss: 15.8058 - val_accuracy: 0.4607\n",
      "Epoch 541/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0312 - accuracy: 0.9937 - val_loss: 15.3064 - val_accuracy: 0.4672\n",
      "Epoch 542/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0279 - accuracy: 0.9944 - val_loss: 16.6979 - val_accuracy: 0.4262\n",
      "Epoch 543/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0267 - accuracy: 0.9953 - val_loss: 15.3400 - val_accuracy: 0.4794\n",
      "Epoch 544/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0327 - accuracy: 0.9937 - val_loss: 15.4045 - val_accuracy: 0.4563\n",
      "Epoch 545/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0264 - accuracy: 0.9948 - val_loss: 15.6281 - val_accuracy: 0.4557\n",
      "Epoch 546/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0265 - accuracy: 0.9951 - val_loss: 15.8875 - val_accuracy: 0.4685\n",
      "Epoch 547/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0302 - accuracy: 0.9940 - val_loss: 15.9201 - val_accuracy: 0.4623\n",
      "Epoch 548/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0321 - accuracy: 0.9940 - val_loss: 16.1594 - val_accuracy: 0.4285\n",
      "Epoch 549/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0230 - accuracy: 0.9955 - val_loss: 15.3856 - val_accuracy: 0.4714\n",
      "Epoch 550/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0316 - accuracy: 0.9943 - val_loss: 16.0139 - val_accuracy: 0.4613\n",
      "Epoch 551/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0265 - accuracy: 0.9945 - val_loss: 16.3437 - val_accuracy: 0.4682\n",
      "Epoch 552/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0286 - accuracy: 0.9942 - val_loss: 15.8443 - val_accuracy: 0.4746\n",
      "Epoch 553/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0388 - accuracy: 0.9933 - val_loss: 16.4709 - val_accuracy: 0.4613\n",
      "Epoch 554/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0429 - accuracy: 0.9925 - val_loss: 18.5927 - val_accuracy: 0.4323\n",
      "Epoch 555/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0366 - accuracy: 0.9936 - val_loss: 16.4486 - val_accuracy: 0.4447\n",
      "Epoch 556/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0275 - accuracy: 0.9939 - val_loss: 17.3107 - val_accuracy: 0.4557\n",
      "Epoch 557/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0395 - accuracy: 0.9930 - val_loss: 18.4673 - val_accuracy: 0.4337\n",
      "Epoch 558/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0320 - accuracy: 0.9932 - val_loss: 17.5956 - val_accuracy: 0.4405\n",
      "Epoch 559/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0329 - accuracy: 0.9943 - val_loss: 17.1470 - val_accuracy: 0.4643\n",
      "Epoch 560/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0331 - accuracy: 0.9934 - val_loss: 17.4725 - val_accuracy: 0.4638\n",
      "Epoch 561/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0362 - accuracy: 0.9937 - val_loss: 16.8634 - val_accuracy: 0.4624\n",
      "Epoch 562/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0372 - accuracy: 0.9926 - val_loss: 17.0229 - val_accuracy: 0.4638\n",
      "Epoch 563/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0363 - accuracy: 0.9931 - val_loss: 18.5157 - val_accuracy: 0.4350\n",
      "Epoch 564/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0454 - accuracy: 0.9920 - val_loss: 16.8811 - val_accuracy: 0.4502\n",
      "Epoch 565/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0327 - accuracy: 0.9939 - val_loss: 16.3614 - val_accuracy: 0.4674\n",
      "Epoch 566/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0344 - accuracy: 0.9940 - val_loss: 16.5235 - val_accuracy: 0.4622\n",
      "Epoch 567/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0321 - accuracy: 0.9944 - val_loss: 16.5209 - val_accuracy: 0.4475\n",
      "Epoch 568/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0238 - accuracy: 0.9949 - val_loss: 16.3864 - val_accuracy: 0.4585\n",
      "Epoch 569/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0333 - accuracy: 0.9939 - val_loss: 15.6835 - val_accuracy: 0.4632\n",
      "Epoch 570/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0254 - accuracy: 0.9947 - val_loss: 15.9801 - val_accuracy: 0.4679\n",
      "Epoch 571/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0265 - accuracy: 0.9945 - val_loss: 17.1057 - val_accuracy: 0.4468\n",
      "Epoch 572/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0313 - accuracy: 0.9939 - val_loss: 17.2098 - val_accuracy: 0.4533\n",
      "Epoch 573/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0225 - accuracy: 0.9953 - val_loss: 16.6845 - val_accuracy: 0.4504\n",
      "Epoch 574/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0336 - accuracy: 0.9938 - val_loss: 16.5498 - val_accuracy: 0.4614\n",
      "Epoch 575/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0220 - accuracy: 0.9949 - val_loss: 17.0743 - val_accuracy: 0.4600\n",
      "Epoch 576/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0314 - accuracy: 0.9943 - val_loss: 17.0864 - val_accuracy: 0.4438\n",
      "Epoch 577/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0294 - accuracy: 0.9947 - val_loss: 17.5892 - val_accuracy: 0.4448\n",
      "Epoch 578/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0321 - accuracy: 0.9948 - val_loss: 17.1973 - val_accuracy: 0.4527\n",
      "Epoch 579/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0338 - accuracy: 0.9941 - val_loss: 17.1602 - val_accuracy: 0.4625\n",
      "Epoch 580/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0316 - accuracy: 0.9948 - val_loss: 18.0445 - val_accuracy: 0.4646\n",
      "Epoch 581/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0431 - accuracy: 0.9922 - val_loss: 17.5221 - val_accuracy: 0.4559\n",
      "Epoch 582/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0337 - accuracy: 0.9941 - val_loss: 18.5277 - val_accuracy: 0.4587\n",
      "Epoch 583/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0397 - accuracy: 0.9934 - val_loss: 19.2105 - val_accuracy: 0.4320\n",
      "Epoch 584/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0382 - accuracy: 0.9933 - val_loss: 17.9561 - val_accuracy: 0.4580\n",
      "Epoch 585/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0349 - accuracy: 0.9938 - val_loss: 18.4015 - val_accuracy: 0.4453\n",
      "Epoch 586/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0358 - accuracy: 0.9939 - val_loss: 17.7252 - val_accuracy: 0.4627\n",
      "Epoch 587/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0289 - accuracy: 0.9948 - val_loss: 17.4594 - val_accuracy: 0.4556\n",
      "Epoch 588/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0307 - accuracy: 0.9939 - val_loss: 18.8718 - val_accuracy: 0.4373\n",
      "Epoch 589/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0370 - accuracy: 0.9933 - val_loss: 18.2164 - val_accuracy: 0.4422\n",
      "Epoch 590/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0328 - accuracy: 0.9941 - val_loss: 19.4792 - val_accuracy: 0.4199\n",
      "Epoch 591/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0326 - accuracy: 0.9940 - val_loss: 17.6480 - val_accuracy: 0.4524\n",
      "Epoch 592/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0395 - accuracy: 0.9932 - val_loss: 17.9214 - val_accuracy: 0.4492\n",
      "Epoch 593/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0318 - accuracy: 0.9943 - val_loss: 16.5648 - val_accuracy: 0.4776\n",
      "Epoch 594/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0232 - accuracy: 0.9950 - val_loss: 17.1303 - val_accuracy: 0.4693\n",
      "Epoch 595/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0320 - accuracy: 0.9948 - val_loss: 17.3511 - val_accuracy: 0.4658\n",
      "Epoch 596/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0341 - accuracy: 0.9939 - val_loss: 17.0855 - val_accuracy: 0.4543\n",
      "Epoch 597/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0293 - accuracy: 0.9944 - val_loss: 17.9609 - val_accuracy: 0.4514\n",
      "Epoch 598/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0289 - accuracy: 0.9949 - val_loss: 17.1913 - val_accuracy: 0.4633\n",
      "Epoch 599/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0281 - accuracy: 0.9943 - val_loss: 17.7097 - val_accuracy: 0.4563\n",
      "Epoch 600/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0252 - accuracy: 0.9952 - val_loss: 18.5517 - val_accuracy: 0.4443\n",
      "Epoch 601/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0258 - accuracy: 0.9952 - val_loss: 17.5635 - val_accuracy: 0.4748\n",
      "Epoch 602/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0349 - accuracy: 0.9941 - val_loss: 17.7787 - val_accuracy: 0.4591\n",
      "Epoch 603/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0282 - accuracy: 0.9944 - val_loss: 17.0447 - val_accuracy: 0.4602\n",
      "Epoch 604/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0271 - accuracy: 0.9951 - val_loss: 17.7108 - val_accuracy: 0.4736\n",
      "Epoch 605/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0401 - accuracy: 0.9939 - val_loss: 17.7781 - val_accuracy: 0.4746\n",
      "Epoch 606/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0287 - accuracy: 0.9949 - val_loss: 17.6165 - val_accuracy: 0.4742\n",
      "Epoch 607/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0358 - accuracy: 0.9947 - val_loss: 18.0827 - val_accuracy: 0.4683\n",
      "Epoch 608/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0391 - accuracy: 0.9934 - val_loss: 18.5718 - val_accuracy: 0.4458\n",
      "Epoch 609/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0278 - accuracy: 0.9949 - val_loss: 19.2023 - val_accuracy: 0.4492\n",
      "Epoch 610/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0359 - accuracy: 0.9943 - val_loss: 18.9152 - val_accuracy: 0.4478\n",
      "Epoch 611/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0385 - accuracy: 0.9939 - val_loss: 19.6366 - val_accuracy: 0.4420\n",
      "Epoch 612/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0418 - accuracy: 0.9937 - val_loss: 19.0533 - val_accuracy: 0.4522\n",
      "Epoch 613/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0389 - accuracy: 0.9942 - val_loss: 18.9052 - val_accuracy: 0.4532\n",
      "Epoch 614/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0357 - accuracy: 0.9941 - val_loss: 19.3741 - val_accuracy: 0.4635\n",
      "Epoch 615/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0335 - accuracy: 0.9937 - val_loss: 19.1296 - val_accuracy: 0.4546\n",
      "Epoch 616/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0389 - accuracy: 0.9935 - val_loss: 18.8061 - val_accuracy: 0.4542\n",
      "Epoch 617/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0343 - accuracy: 0.9937 - val_loss: 19.0608 - val_accuracy: 0.4577\n",
      "Epoch 618/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0426 - accuracy: 0.9931 - val_loss: 19.9177 - val_accuracy: 0.4285\n",
      "Epoch 619/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0311 - accuracy: 0.9938 - val_loss: 18.0117 - val_accuracy: 0.4505\n",
      "Epoch 620/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0375 - accuracy: 0.9940 - val_loss: 18.4027 - val_accuracy: 0.4642\n",
      "Epoch 621/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0294 - accuracy: 0.9947 - val_loss: 18.1521 - val_accuracy: 0.4643\n",
      "Epoch 622/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0352 - accuracy: 0.9946 - val_loss: 17.7521 - val_accuracy: 0.4713\n",
      "Epoch 623/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0290 - accuracy: 0.9953 - val_loss: 17.6559 - val_accuracy: 0.4607\n",
      "Epoch 624/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0286 - accuracy: 0.9943 - val_loss: 18.5418 - val_accuracy: 0.4501\n",
      "Epoch 625/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0171 - accuracy: 0.9966 - val_loss: 17.8112 - val_accuracy: 0.4690\n",
      "Epoch 626/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0350 - accuracy: 0.9942 - val_loss: 19.1691 - val_accuracy: 0.4423\n",
      "Epoch 627/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0278 - accuracy: 0.9952 - val_loss: 18.3043 - val_accuracy: 0.4463\n",
      "Epoch 628/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0259 - accuracy: 0.9952 - val_loss: 18.0379 - val_accuracy: 0.4630\n",
      "Epoch 629/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0287 - accuracy: 0.9951 - val_loss: 18.4132 - val_accuracy: 0.4472\n",
      "Epoch 630/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0251 - accuracy: 0.9954 - val_loss: 17.9932 - val_accuracy: 0.4703\n",
      "Epoch 631/15000\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0276 - accuracy: 0.9946 - val_loss: 17.9833 - val_accuracy: 0.4663\n",
      "Epoch 632/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0283 - accuracy: 0.9949 - val_loss: 18.1285 - val_accuracy: 0.4564\n",
      "Epoch 633/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0271 - accuracy: 0.9951 - val_loss: 18.5534 - val_accuracy: 0.4680\n",
      "Epoch 634/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0273 - accuracy: 0.9950 - val_loss: 18.4094 - val_accuracy: 0.4688\n",
      "Epoch 635/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0327 - accuracy: 0.9941 - val_loss: 20.7737 - val_accuracy: 0.4343\n",
      "Epoch 636/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0347 - accuracy: 0.9942 - val_loss: 19.2316 - val_accuracy: 0.4567\n",
      "Epoch 637/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0328 - accuracy: 0.9946 - val_loss: 19.5256 - val_accuracy: 0.4599\n",
      "Epoch 638/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0390 - accuracy: 0.9940 - val_loss: 18.8196 - val_accuracy: 0.4585\n",
      "Epoch 639/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0327 - accuracy: 0.9939 - val_loss: 19.5410 - val_accuracy: 0.4562\n",
      "Epoch 640/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0331 - accuracy: 0.9941 - val_loss: 21.0148 - val_accuracy: 0.4326\n",
      "Epoch 641/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0363 - accuracy: 0.9950 - val_loss: 20.0963 - val_accuracy: 0.4490\n",
      "Epoch 642/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0297 - accuracy: 0.9949 - val_loss: 18.8269 - val_accuracy: 0.4808\n",
      "Epoch 643/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0359 - accuracy: 0.9938 - val_loss: 20.0568 - val_accuracy: 0.4527\n",
      "Epoch 644/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0332 - accuracy: 0.9942 - val_loss: 19.8521 - val_accuracy: 0.4622\n",
      "Epoch 645/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0383 - accuracy: 0.9940 - val_loss: 20.2547 - val_accuracy: 0.4555\n",
      "Epoch 646/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0345 - accuracy: 0.9942 - val_loss: 19.8845 - val_accuracy: 0.4449\n",
      "Epoch 647/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0358 - accuracy: 0.9938 - val_loss: 18.8223 - val_accuracy: 0.4632\n",
      "Epoch 648/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0230 - accuracy: 0.9958 - val_loss: 18.4472 - val_accuracy: 0.4727\n",
      "Epoch 649/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0292 - accuracy: 0.9951 - val_loss: 18.6546 - val_accuracy: 0.4630\n",
      "Epoch 650/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0320 - accuracy: 0.9949 - val_loss: 18.3492 - val_accuracy: 0.4728\n",
      "Epoch 651/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0307 - accuracy: 0.9948 - val_loss: 18.5196 - val_accuracy: 0.4633\n",
      "Epoch 652/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0240 - accuracy: 0.9954 - val_loss: 19.3794 - val_accuracy: 0.4562\n",
      "Epoch 653/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0265 - accuracy: 0.9955 - val_loss: 20.1003 - val_accuracy: 0.4435\n",
      "Epoch 654/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0262 - accuracy: 0.9950 - val_loss: 19.2210 - val_accuracy: 0.4693\n",
      "Epoch 655/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0304 - accuracy: 0.9950 - val_loss: 19.8052 - val_accuracy: 0.4515\n",
      "Epoch 656/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0283 - accuracy: 0.9955 - val_loss: 19.4810 - val_accuracy: 0.4642\n",
      "Epoch 657/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0257 - accuracy: 0.9951 - val_loss: 18.6348 - val_accuracy: 0.4698\n",
      "Epoch 658/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0260 - accuracy: 0.9951 - val_loss: 18.6961 - val_accuracy: 0.4640\n",
      "Epoch 659/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0264 - accuracy: 0.9959 - val_loss: 18.9026 - val_accuracy: 0.4610\n",
      "Epoch 660/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0309 - accuracy: 0.9953 - val_loss: 18.8340 - val_accuracy: 0.4645\n",
      "Epoch 661/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0261 - accuracy: 0.9956 - val_loss: 19.8318 - val_accuracy: 0.4666\n",
      "Epoch 662/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0326 - accuracy: 0.9949 - val_loss: 19.1090 - val_accuracy: 0.4699\n",
      "Epoch 663/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0336 - accuracy: 0.9943 - val_loss: 20.0557 - val_accuracy: 0.4588\n",
      "Epoch 664/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0357 - accuracy: 0.9940 - val_loss: 20.4815 - val_accuracy: 0.4599\n",
      "Epoch 665/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0441 - accuracy: 0.9937 - val_loss: 20.1577 - val_accuracy: 0.4580\n",
      "Epoch 666/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0403 - accuracy: 0.9935 - val_loss: 20.9549 - val_accuracy: 0.4517\n",
      "Epoch 667/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0410 - accuracy: 0.9939 - val_loss: 20.0750 - val_accuracy: 0.4536\n",
      "Epoch 668/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0333 - accuracy: 0.9948 - val_loss: 19.6424 - val_accuracy: 0.4628\n",
      "Epoch 669/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0288 - accuracy: 0.9949 - val_loss: 19.6556 - val_accuracy: 0.4742\n",
      "Epoch 670/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0320 - accuracy: 0.9946 - val_loss: 20.6749 - val_accuracy: 0.4699\n",
      "Epoch 671/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0326 - accuracy: 0.9943 - val_loss: 20.7845 - val_accuracy: 0.4640\n",
      "Epoch 672/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0343 - accuracy: 0.9948 - val_loss: 21.0588 - val_accuracy: 0.4486\n",
      "Epoch 673/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0336 - accuracy: 0.9937 - val_loss: 22.1377 - val_accuracy: 0.4336\n",
      "Epoch 674/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0297 - accuracy: 0.9951 - val_loss: 20.5976 - val_accuracy: 0.4526\n",
      "Epoch 675/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0405 - accuracy: 0.9939 - val_loss: 19.0584 - val_accuracy: 0.4699\n",
      "Epoch 676/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0321 - accuracy: 0.9946 - val_loss: 19.9627 - val_accuracy: 0.4651\n",
      "Epoch 677/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0267 - accuracy: 0.9955 - val_loss: 19.5268 - val_accuracy: 0.4701\n",
      "Epoch 678/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0318 - accuracy: 0.9948 - val_loss: 20.0912 - val_accuracy: 0.4561\n",
      "Epoch 679/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0318 - accuracy: 0.9950 - val_loss: 20.2281 - val_accuracy: 0.4397\n",
      "Epoch 680/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0176 - accuracy: 0.9969 - val_loss: 19.0344 - val_accuracy: 0.4776\n",
      "Epoch 681/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0315 - accuracy: 0.9949 - val_loss: 19.5948 - val_accuracy: 0.4596\n",
      "Epoch 682/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0253 - accuracy: 0.9959 - val_loss: 20.2927 - val_accuracy: 0.4564\n",
      "Epoch 683/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0290 - accuracy: 0.9953 - val_loss: 19.6210 - val_accuracy: 0.4693\n",
      "Epoch 684/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0265 - accuracy: 0.9951 - val_loss: 19.4798 - val_accuracy: 0.4743\n",
      "Epoch 685/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0240 - accuracy: 0.9964 - val_loss: 20.4818 - val_accuracy: 0.4389\n",
      "Epoch 686/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0231 - accuracy: 0.9959 - val_loss: 19.3655 - val_accuracy: 0.4714\n",
      "Epoch 687/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0397 - accuracy: 0.9946 - val_loss: 19.1919 - val_accuracy: 0.4728\n",
      "Epoch 688/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0308 - accuracy: 0.9948 - val_loss: 20.0508 - val_accuracy: 0.4755\n",
      "Epoch 689/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0267 - accuracy: 0.9957 - val_loss: 20.2141 - val_accuracy: 0.4813\n",
      "Epoch 690/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0310 - accuracy: 0.9951 - val_loss: 20.2556 - val_accuracy: 0.4640\n",
      "Epoch 691/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0362 - accuracy: 0.9939 - val_loss: 22.6966 - val_accuracy: 0.4455\n",
      "Epoch 692/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0318 - accuracy: 0.9953 - val_loss: 19.9545 - val_accuracy: 0.4706\n",
      "Epoch 693/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0282 - accuracy: 0.9950 - val_loss: 22.1561 - val_accuracy: 0.4424\n",
      "Epoch 694/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0373 - accuracy: 0.9944 - val_loss: 21.8807 - val_accuracy: 0.4577\n",
      "Epoch 695/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0319 - accuracy: 0.9946 - val_loss: 22.0820 - val_accuracy: 0.4552\n",
      "Epoch 696/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0285 - accuracy: 0.9954 - val_loss: 21.7745 - val_accuracy: 0.4677\n",
      "Epoch 697/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0274 - accuracy: 0.9952 - val_loss: 20.8660 - val_accuracy: 0.4735\n",
      "Epoch 698/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0312 - accuracy: 0.9948 - val_loss: 21.3321 - val_accuracy: 0.4654\n",
      "Epoch 699/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0315 - accuracy: 0.9946 - val_loss: 22.3870 - val_accuracy: 0.4536\n",
      "Epoch 700/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0342 - accuracy: 0.9942 - val_loss: 22.3382 - val_accuracy: 0.4412\n",
      "Epoch 701/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0351 - accuracy: 0.9937 - val_loss: 21.1795 - val_accuracy: 0.4618\n",
      "Epoch 702/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0366 - accuracy: 0.9948 - val_loss: 20.4151 - val_accuracy: 0.4702\n",
      "Epoch 703/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0287 - accuracy: 0.9956 - val_loss: 20.0779 - val_accuracy: 0.4705\n",
      "Epoch 704/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0269 - accuracy: 0.9960 - val_loss: 19.9430 - val_accuracy: 0.4728\n",
      "Epoch 705/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0233 - accuracy: 0.9961 - val_loss: 22.0030 - val_accuracy: 0.4475\n",
      "Epoch 706/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0320 - accuracy: 0.9953 - val_loss: 20.3675 - val_accuracy: 0.4712\n",
      "Epoch 707/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0246 - accuracy: 0.9960 - val_loss: 20.6769 - val_accuracy: 0.4724\n",
      "Epoch 708/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0293 - accuracy: 0.9952 - val_loss: 21.4129 - val_accuracy: 0.4481\n",
      "Epoch 709/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0278 - accuracy: 0.9953 - val_loss: 21.4445 - val_accuracy: 0.4618\n",
      "Epoch 710/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0250 - accuracy: 0.9958 - val_loss: 20.2879 - val_accuracy: 0.4673\n",
      "Epoch 711/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0267 - accuracy: 0.9957 - val_loss: 20.8122 - val_accuracy: 0.4713\n",
      "Epoch 712/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0281 - accuracy: 0.9951 - val_loss: 20.6796 - val_accuracy: 0.4743\n",
      "Epoch 713/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0321 - accuracy: 0.9953 - val_loss: 20.4581 - val_accuracy: 0.4593\n",
      "Epoch 714/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0292 - accuracy: 0.9960 - val_loss: 20.7827 - val_accuracy: 0.4504\n",
      "Epoch 715/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0344 - accuracy: 0.9948 - val_loss: 20.8338 - val_accuracy: 0.4621\n",
      "Epoch 716/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0247 - accuracy: 0.9959 - val_loss: 21.2332 - val_accuracy: 0.4770\n",
      "Epoch 717/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0255 - accuracy: 0.9950 - val_loss: 22.4375 - val_accuracy: 0.4620\n",
      "Epoch 718/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0387 - accuracy: 0.9945 - val_loss: 22.4710 - val_accuracy: 0.4554\n",
      "Epoch 719/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0238 - accuracy: 0.9953 - val_loss: 23.0058 - val_accuracy: 0.4614\n",
      "Epoch 720/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0313 - accuracy: 0.9954 - val_loss: 22.3595 - val_accuracy: 0.4505\n",
      "Epoch 721/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0340 - accuracy: 0.9949 - val_loss: 21.7950 - val_accuracy: 0.4681\n",
      "Epoch 722/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0338 - accuracy: 0.9947 - val_loss: 22.3036 - val_accuracy: 0.4558\n",
      "Epoch 723/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0351 - accuracy: 0.9949 - val_loss: 21.8579 - val_accuracy: 0.4701\n",
      "Epoch 724/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0371 - accuracy: 0.9948 - val_loss: 22.3749 - val_accuracy: 0.4557\n",
      "Epoch 725/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0356 - accuracy: 0.9948 - val_loss: 23.5936 - val_accuracy: 0.4313\n",
      "Epoch 726/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0310 - accuracy: 0.9951 - val_loss: 23.2531 - val_accuracy: 0.4479\n",
      "Epoch 727/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0430 - accuracy: 0.9941 - val_loss: 22.6512 - val_accuracy: 0.4466\n",
      "Epoch 728/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0327 - accuracy: 0.9946 - val_loss: 21.9241 - val_accuracy: 0.4581\n",
      "Epoch 729/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0292 - accuracy: 0.9944 - val_loss: 21.1550 - val_accuracy: 0.4545\n",
      "Epoch 730/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0353 - accuracy: 0.9950 - val_loss: 20.3250 - val_accuracy: 0.4652\n",
      "Epoch 731/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0290 - accuracy: 0.9958 - val_loss: 21.2162 - val_accuracy: 0.4729\n",
      "Epoch 732/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0302 - accuracy: 0.9956 - val_loss: 22.7171 - val_accuracy: 0.4611\n",
      "Epoch 733/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0318 - accuracy: 0.9951 - val_loss: 21.0379 - val_accuracy: 0.4592\n",
      "Epoch 734/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0229 - accuracy: 0.9957 - val_loss: 22.0815 - val_accuracy: 0.4581\n",
      "Epoch 735/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0158 - accuracy: 0.9968 - val_loss: 21.2358 - val_accuracy: 0.4651\n",
      "Epoch 736/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0284 - accuracy: 0.9955 - val_loss: 21.9054 - val_accuracy: 0.4645\n",
      "Epoch 737/15000\n",
      "1024/1024 [==============================] - 15s 15ms/step - loss: 0.0216 - accuracy: 0.9960 - val_loss: 23.2433 - val_accuracy: 0.4462\n",
      "Epoch 738/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0310 - accuracy: 0.9958 - val_loss: 21.4639 - val_accuracy: 0.4660\n",
      "Epoch 739/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0323 - accuracy: 0.9951 - val_loss: 20.6905 - val_accuracy: 0.4729\n",
      "Epoch 740/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0219 - accuracy: 0.9962 - val_loss: 20.8357 - val_accuracy: 0.4717\n",
      "Epoch 741/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0191 - accuracy: 0.9966 - val_loss: 22.0748 - val_accuracy: 0.4653\n",
      "Epoch 742/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0345 - accuracy: 0.9950 - val_loss: 21.9402 - val_accuracy: 0.4731\n",
      "Epoch 743/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0245 - accuracy: 0.9957 - val_loss: 22.0921 - val_accuracy: 0.4798\n",
      "Epoch 744/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0251 - accuracy: 0.9963 - val_loss: 22.5414 - val_accuracy: 0.4708\n",
      "Epoch 745/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0296 - accuracy: 0.9953 - val_loss: 23.4641 - val_accuracy: 0.4493\n",
      "Epoch 746/15000\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.0269 - accuracy: 0.9956 - val_loss: 23.9523 - val_accuracy: 0.4584\n",
      "Epoch 747/15000\n",
      "1024/1024 [==============================] - 14s 13ms/step - loss: 0.0362 - accuracy: 0.9949 - val_loss: 22.6999 - val_accuracy: 0.4635\n",
      "Epoch 748/15000\n",
      " 388/1024 [==========>...................] - ETA: 6s - loss: 0.0206 - accuracy: 0.9965"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:07:26 05.08 \u001b[1mINFO\u001b[0m 1599783940.py:49]: keras model saved.\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
